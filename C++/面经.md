# C++

## 语法

### 宏定义和 typedef 区别？

- 宏定义主要定义常量及复杂内容， typedef 是给定义类型起别名
- 宏替换发生在预处理阶段，属于文本插入替换， typedef 是编译的一部分
- 宏定义不检查类型， typedef 会检查数据类型
- 宏定义不是语句，不用加分号， typedef 是语句，要加分号标识结束



### 定义和声明的区别？

**对于变量**：声明只是告诉编译器，有某个类型的变量将要被使用，但是并不会为其分配内存。而定义就会直接分配内存

**对于函数**：声明一般都在头文件里，告诉编译器存在这个函数。而定义一般都在源文件里，是函数的具体实现

- 声明仅仅只是告诉编译器某个类型的变量以及函数存在，不会分配具体的内存，定义会在定义的地方分配存储空间
- 相同的变量可以多处声明，但是只能在一处定义



### 指针和引用的区别

1. 指针是一个变量，存储的是地址，而引用是变量的别名
2. 指针可以有多级，而引用只有一级
3. 指针可以是空，而引用不能是空，且定义时必须初始化
4. 指针在初始化后可以改变指向，而引用在初始化后不能改变



### 在传递函数参数时，什么时候该使用指针，什么时候该使用引用呢？

- 传入的是数组的，用指针
- 有可能传入空指针的，用指针
- 传入的内容会被修改的，用指针
- 可能改变对象生命周期的，用指针
- 临时借用，不会改变对象生命周期的，用引用



### 正确区分以下四种指针？

```C++
 int *p[10] 
 int (*p)[10]
 int *p(int)
 int (*p)(int) 
```

1. int *p[10]

int *p[10] 是指针数组。强调的是数组的概念。简单的讲，可以理解为定义了一个数组，数组内的元素其数据类型为int *指针。

常见的使用方式如下：

```C++
int *p_arr[10];
int *p1 = nullptr;
p_arr[0] = p1;
```

2. int (*p)[10]

` int (*p)[10]`为指针数组。强调的是指针的概念。指针`p`指向一个长度等于10，数据类型为`int`的数组

```C++
int (*arr_p)[10] = new int[5][10];
cout << " address of arr_p" " << arr_p << endl;
arr_p++;
cout << " address of arr_p" " << arr_p << endl;
```

3. int *p(int)

`int *p(int)`是函数声明：返回类型为`int *`，形参为`int`的函数

4. int (*p)(int)

`int (*p)(int)`是函数指针。函数指针是指向函数的指针

```C++
// 函数指针
int (*func_p)(int);
// 定义一个函数
int testFunc(int a){
    cout << "a : " << a << endl;
}
int main(){
    func_p = testFunc;
    func_p(5);
    return 0;
}
```















### 初始化和赋值的区别

- 对于简单类型来说，没什么区别
- 对于类和复杂类型来说，初始化会调用拷贝构造函数，赋值会调用重载的赋值运算符



### 全局变量和局部变量

- 生命周期不同，全局变量随主程序的创建而创建，销毁而销毁，局部变量随某个函数或者循环创建以及销毁
- 位置不同，全局变量分配在全局数据区，各个程序的各个部分都能用到。而局部变量分配在 堆栈区，只能局部使用



### 形参和实参的区别

- 时间上来看，形参只有在函数别调用的时候，才会在堆栈区分配内存，并且只能在函数内部使用，函数结束就会销毁内存。而实参在函数调用的时候，必须有确定的值。
- 从数量及类型上看，实参和形参必须是一一对应的，包括数量，类型都应该严格一致
- 从数据流流向来看，只能把实参的值传递给形参，而不能把形参的值传递给实参，因此，函数调用的时候，形参的值会发生改变而实参不会。而如果是引用或者指针类型，那么形参改变而实参也会跟着变化



### 常量指针和指针常量区别？

- **常量指针（底层 const）**：定义了一个指针，指向一个只读的对象。不能改变对象的值。强调指针所指对象的不可改变性
- 常量是常量

```C++
int temp = 10;
const int* a = &temp;
int const *a = &temp

*a = 9; //错误
```



- **指针常量（顶层 const）:** 定义了一个指针，指针的值初始化后不可改变
- 常量是指针， (* a) 和 (* const a)

```C++
int temp = 10;
int temp1 = 20;

int* const p = &temp;

p = &temp2;	// 错读
```

 

### 静态变量什么时候初始化？

静态变量存储在虚拟地址空间的数据段和bss段，c语言中其在代码执行之前初始化，属于编译期初始化。

而c++中由于引入了对象，对象生成必须调用构造函数，因此c++中规定全局或者局部静态对象当且仅当对象首次用到时进行构造。



### C++中const和static的作用

**static:**

不考虑类的情况

- 隐藏，不加 static 的全局变量和函数具有全局可见性，可以在其他文件使用，加 static 之后只能在文件所在的编译模块使用
- 默认初始化是 0，包括未初始化的全局静态变量和局部静态变量，存在 .bss 段
- 静态变量在函数内定义，始终存在，且只进行一次初始化，作用范围和局部变量相同，函数退出后仍然存在，但不能使用

考虑类的情况：

- static成员变量：只属于类，不和对象关联，所有对象共享类的静态成员变量。**必须在类中声明，在类外定义**。
- static成员函数：不具有this指针，只能访问静态成员变量和静态成员函数；**不能被声明为const、虚函数和volatile**；可以被非static成员函数任意访问

**const**：

不考虑类的情况

- const 常量在定义时初始化，后续不可更改
- const 形参可以接受 const 和 非 const 类型的实参

考虑类的情况

- const 成员变量：只能在**构造函数初始化列表**中对const类型成员变量初始化。不能在构造函数中初始化const类型成员变量
- const 成员函数：可以使用类中的所有成员变量，但是不能修改它们的值。`    int getage() const;` 
- const 修饰对象指的是对象是一个常量，常量对象的数据成员在对象创建后不能修改，并且常量对象只能调用const成员函数（因为常量对象的地址是const类型的，它调用成员函数需要将地址传给成员函数的this指针，那么这个指针必须const类型的，而const成员函数的this指针就是const类型的）



### final和override关键字？

**override：**当在父类中使用了虚函数时候，指定了子类的这个虚函数是重写父类的

```C++
class A
{
    virtual void foo();
};
class B : public A
{
    virtual void f00(); //OK，这个函数是B新增的，不是继承的
    virtual void f0o() override; //Error, 加了override之后，这个函数一定是继承自A的，A找不到就报错，这里的 f0o 并不是父类的虚函数
};

```



**final:** 当不希望某个类被继承，或不希望某个虚函数被重写，可以在类名和虚函数后添加final关键字，添加final关键字后被继承或重写，编译器会报错

```C++
class Base
{
    virtual void foo();
};
 
class A : public Base
{
    void foo() final; // foo 被override并且是最后一个override，在其子类中不可以重写
};

class B final : A // 指明B是不可以被继承的
{
    void foo() override; // Error: 在A中已经被final了
};
 
class C : B // Error: B is final
{
};
```



### 直接初始化和拷贝初始化?

 **直接初始化：** 直接调用和实参匹配的构造函数（包括拷贝构造函数）

**拷贝初始化：** 首先使用指定的构造函数创建一个临时对象，然后调用拷贝构造函数

拷贝初始化和赋值运算符重载的区别在于 左边的对象是否存在

```C++
string str1("I am a string");//语句1 直接初始化
string str2(str1);//语句2 直接初始化，str1是已经存在的对象，直接调用拷贝构造函数对str2进行初始化
string str3 = "I am a string";//语句3 拷贝初始化，先为字符串”I am a string“创建临时对象，再把临时对象作为参数，使用拷贝构造函数构造str3
string str4 = str1;//语句4 拷贝初始化，这里相当于隐式调用拷贝构造函数，而不是调用赋值运算符函数？？？？？？为啥不是赋值运算符重载
```



### 野指针和悬空指针？

都是执行无效内存区域的指针，访问会带来未定义行为

- 野指针：没有初始化的指针

```C++
int main(void) { 
    
    int* p;     // 未初始化
    std::cout<< *p << std::endl; // 未初始化就被使用
    
    return 0;
}
```

- 悬空指针：指针最初指向的内存已经被释放了的指针

```C++
int main(void) { 
  int * p = nullptr;
  int* p2 = new int;
  
  p = p2;

  delete p2;
}
```



### C++中的重载、重写（覆盖）的区别？

- 重载（overload）：对同一定义范围内的函数，多个不同的实现版本。**函数名相同，参数类型、数量和顺序不同**
- 重写（override）：子类在继承父类的时候，重写父类的方法
  - 父类的函数必须是虚函数
  - 重写的函数的参数列表，返回值，所抛出的异常与被重写的方法一致
  - 被重写的函数不能是 private
  - 静态函数不能被重写成非静态函数



### C++有哪几种的构造函数？

- 默认构造函数
- 初始化构造函数（有参数）
- 拷贝构造函数
- 移动构造函数（move和右值引用）
- 委托构造函数
- 转换构造函数

```C++
#include <iostream>
using namespace std;

class Student{
public:
    Student(){//默认构造函数，没有参数
        this->age = 20;
        this->num = 1000;
    };  
    Student(int a, int n):age(a), num(n){}; //初始化构造函数，有参数和参数列表
    Student(const Student& s){//拷贝构造函数，这里与编译器生成的一致
        this->age = s.age;
        this->num = s.num;
    }; 
    Student(int r){   //转换构造函数,形参是其他类型变量，且只有一个形参
        this->age = r;
		this->num = 1002;
    };
    ~Student(){}
public:
    int age;
    int num;
};

int main(){
    Student s1;
    Student s2(18,1001);
    int a = 10;
    Student s3(a);
    Student s4(s3);
    
    printf("s1 age:%d, num:%d\n", s1.age, s1.num);
    printf("s2 age:%d, num:%d\n", s2.age, s2.num);
    printf("s3 age:%d, num:%d\n", s3.age, s3.num);
    printf("s2 age:%d, num:%d\n", s4.age, s4.num);
    return 0;
}
//运行结果
//s1 age:20, num:1000
//s2 age:18, num:1001
//s3 age:10, num:1002
//s2 age:10, num:1002
```



### 浅拷贝和深拷贝的区别?

浅拷贝只是拷贝一个指针，并没有开辟新的空间存储拷贝的内容，如果原来的指针释放了资源。那么再使用浅拷贝的指针就会出现错误

深拷贝不仅拷贝值，还会开辟新的空间存放拷贝内容，这样，即使原来的指针释放了资源，也不会影响深拷贝得到的值

```C++
#include <iostream>  
#include <string.h>
using namespace std;
 
class Student
{
private:
	int num;
	char *name;
public:
	Student(){
        name = new char(20);
		cout << "Student" << endl;
    };
	~Student(){
        cout << "~Student " << &name << endl;
        delete name;
        name = NULL;
    };
	Student(const Student &s){//拷贝构造函数
        //浅拷贝，当对象的name和传入对象的name指向相同的地址
        name = s.name;
        //深拷贝
        //name = new char(20);
        //memcpy(name, s.name, strlen(s.name));
        cout << "copy Student" << endl;
    };
};
 
int main()
{
	{// 花括号让s1和s2变成局部对象，方便测试
		Student s1;
		Student s2(s1);// 复制对象
	}
	system("pause");
	return 0;
}
//浅拷贝执行结果：
//Student
//copy Student
//~Student 0x7fffed0c3ec0
//~Student 0x7fffed0c3ed0
//*** Error in `/tmp/815453382/a.out': double free or corruption (fasttop): 0x0000000001c82c20 ***

//深拷贝执行结果：
//Student
//copy Student
//~Student 0x7fffebca9fb0
//~Student 0x7fffebca9fc0
```



### 内联函数和宏定义的区别?

- 宏定义只是在预编译的时候做简单的字符串替换，而内联函数是个函数，编译时会进行类型检查
- 内联函数在编译的时候直接把代码嵌入到目标代码中，省去了函数调用带来的开销



### volatile、mutable和explicit关键字的用法？

**volatile** 

是一种类型修饰符，**volatile定义变量的值是易变的，每次用到这个变量的值的时候都要去重新读取这个变量的值，而不是读寄存器内的备份**

**多线程中被几个任务共享的变量需要定义为volatile类型。**这样每次读取数据就会重新读取，而不是寄存器的备份？



**mutable** 

中文意思是“可变的，易变的”，是为了突破const的限制而设置的。

在 const 函数中，不能改变对象的状态，但是被 mutable 修饰的变量，将永远处于可变的状态，是可以改变的

```C++
class person
{
int m_A;
mutable int m_B;//特殊变量 在常函数里值也可以被修改
public:
     void add() const//在函数里不可修改this指针指向的值 常量指针
     {
        m_A=10;//错误  不可修改值，this已经被修饰为常量指针
        m_B=20;//正确
     }
}

class person
{
int m_A;
mutable int m_B;//特殊变量 在常函数里值也可以被修改
}
int main()
{
const person p;//修饰常对象 不可修改类成员的值
p.m_A=10;//错误，被修饰了指针常量
p.m_B=200;//正确，特殊变量，修饰了mutable
}
```



**explicit** 

关键字用来修饰类的构造函数，被修饰的构造函数的类，不能发生相应的隐式类型转换，只能以**显示的方式进行类型转换**

- explicit 关键字只能用于类内部的构造函数声明上
- explicit 关键字作用于单个参数的构造函数
- 被explicit修饰的构造函数的类，不能发生相应的隐式类型转换



### 什么是c++隐式类型转换？

C++语言不会直接将两个不同类型的值相加，而是先根据**类型转换规则**设法**将运算对象的类型统一后再求值**。上述的类型转换是**自动执行**的，它们被称作**隐式转换**



### 什么情况下会调用拷贝构造函数？

- 用类的实例化对象去初始化新对象的时候
- 函数的形参是类的对象时
- 函数返回值是函数中类的局部对象时

```C++
class A
{
public:
	A() {};
	A(const A& a)
	{
		cout << "copy constructor is called" << endl;
	};
	~A() {};
};

void useClassA(A a) {}

A getClassA()//此时会发生拷贝构造函数的调用，虽然发生NRV优化，但是依然调用拷贝构造函数
{
	A a;
	return a;
}


//A& getClassA2()//  VS2019下，此时编辑器会进行（Named return Value优化）NRV优化,不调用拷贝构造函数 ，如果是引用传递的方式返回当前函数体内生成的对象时，并不发生拷贝构造函数的调用
//{
//	A a;
//	return a;
//}


int main()
{
	A a1,a3,a4;
	A a2 = a1;  //调用拷贝构造函数,对应情况1
	useClassA(a1);//调用拷贝构造函数，对应情况2
	a3 = getClassA();//发生NRV优化，但是值返回，依然会有拷贝构造函数的调用 情况3
	a4 = getClassA2(a1);//发生NRV优化，且引用返回自身，不会调用
    return 0;
}

```



### C++中新增了string，它与C语言中的 char *有什么区别吗？它是如何实现的？

string 是STL当中的一个容器, 其实是对char* 进行了封装，封装的string包含了char *数组，容量，长度等等属性

- string 的内存管理是系统实现的，而 char * 需要用户自己处理
- string 还可以使用各种成员函数来处理串的每一个字符



### 对象复用的了解，零拷贝的了解？

对象复用其本质是一种设计模式：Flyweight享元模式。

通过将对象存储到“对象池”中实现对象的重复利用，这样可以避免多次创建重复对象的开销，节约系统资源。



**零拷贝：** 避免 CPU 把数据从一块存储拷贝到另外一块存储的技术，可以减少数据拷贝和共享总线操作的次数

C++ 中，emplace_back() 就是运用了零拷贝技术，和 push_back 一样，区别在于，使用 push_back() 需要调用拷贝构造函数和转移构造函数，而 emplace_back() 插入的元素原地构造



### 为什么不能把所有的函数写成内联函数?

**空间：**内联函数的调用需要复制代码，如果代码过于复杂，就会浪费内存空间

**时间：**另外，如果代码过于复杂，执行时间比函数调用的开销还要大，也没有太大意义









## 面向对象

### 介绍面向对象的三大特性，并且举例说明？

1. 封装：把客观事物封装成抽象的类，并且类可以给自己的数据和方法设置访问权限，通过权限来限制其他类的对象的访问

2. 继承：让某一个抽象类获得另一个抽象类的数据和方法。他可以使用父类的数据和方法，也可以自己定义自己的数据和方法，还能对父类的方法进行重写

3. 多态：同一事物表现出不同事物的能力，即向不同对象发送同一消息，不同的对象在接收时会产生不同的行为**（重载实现编译时多态，虚函数实现运行时多态）**。**简单一句话：允许将子类类型的指针赋值给父类类型的指针**

   实现多态有二种方式：重写（override），重载（overload）。

   重写：是指子类重新定义父类的虚函数的做法。

   重载：是指允许存在多个同名函数，而这些函数的参数表不同（或许参数个数不同，或许参数类型不同，或许两者都不同）

   





### C++中struct和class的区别？

相同点：

- 都有成员变量，成员函数，私有，公有等概念
- 能用 class 完成的，都可以用 struct 完成

不同点：

- class 成员默认是私有的，struct 成员默认是共有的
- class 默认是 私有继承，struct 默认是公有继承



### public，protected和private访问和继承权限/public/protected/private的区别？

- public的变量和函数在类的内部外部都可以访问。
- protected的变量和函数只能在类的内部和其派生类中访问。
- private修饰的元素只能在类内访问。

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230420113615.png)

其实就是 继承权限的方式决定了最终在类内的方式（缩小父类的权限），下面在类内进行讨论

- public 继承就是和父类的权限一样
- protected， private 继承就是把父类更低的权限提高



### 如何用代码判断大小端存储？

- 大端存储：数据的高字节部分存放到低地址中
- 小端存储：数据的低字节部分存放到低地址中

例如：4字节的数字0x12345678

大端存储：

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230420115514.png)

小端存储：

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230420115548.png)





### 类成员初始化方式？构造函数的执行顺序 ？为什么用成员初始化列表会快一些？

列表初始化: 给数据成员分配内存空间时就进行初始化

赋值初始化: 在函数体中初始化,是在所有的数据成员被分配内存空间后才进行的



① 虚拟基类的构造函数（多个虚拟基类则按照继承的顺序执行构造函数）。

② 基类的构造函数（多个普通基类也按照继承的顺序执行构造函数）。

③ 类类型的成员对象的构造函数（按照初始化顺序）

④ 派生类自己的构造函数。

 

C++的赋值操作是会产生临时对象的。临时对象的出现会降低程序的效率。因此直接初始化更快



### 有哪些情况必须用到成员列表初始化？作用是什么？

- 初始化一个 const 成员变量
- 初始化一个 引用成员变量
- 调用基类的构造函数
- 调用一个成员类的构造函数的时候



成员初始化列表做了什么？

编译器会一一操作初始化列表，以适当的顺序在构造函数之内安插初始化操作，并且在任何显示用户代码之前；

list中的项目顺序是由**类中的成员声明顺序决定的**，不是由初始化列表的顺序决定的；



### 说说移动构造函数？

调用拷贝构造函数初始化的时候，例如对象 a 初始化对象 b，初始化结束后如果 a 被使用并且没析构，那为什么不直接拷贝 a 的指针，使用 a 的空间呢？这样就避免了新的空间的分配，大大降低了构造的成本。这就是移动构造函数设计的初衷

拷贝构造函数中，对于指针，采用深拷贝，而移动构造函数中，只需要浅拷贝就行。只需要避免 a 的指针释放空间。于是可以把 a 对象的指针置为 NULL，这样调用析构函数的时候，不会收回 a 的对象空间

移动构造函数的参数和拷贝构造函数不同，拷贝构造函数的参数是一个左值引用，但是移动构造函数的初值是一个右值引用。意味着，移动构造函数的参数是一个右值或者将亡值的引用。也就是说，只有用一个右值，或者将亡值初始化另一个对象的时候，才会调用移动构造函数。而那个move语句，就是将一个左值变成一个将亡值



### C++中将临时变量作为返回值时的处理过程?

临时变量，在函数调用过程中是被压到程序进程的栈中的，当函数退出时，临时变量出栈，即临时变量已经被销毁

函数调用结束后，返回值被临时存储到寄存器中，并没有放到堆或栈中，也就是说与内存没有关系了。当退出函数的时候，临时变量可能被销毁，但是返回值却被放到寄存器中与临时变量的生命周期没有关系



### 静态类型和动态类型，静态绑定和动态绑定的介绍?

- 静态类型：对象在声明时采用的类型，在编译期既已确定；
- 动态类型：通常是指一个指针或引用目前所指对象的类型，是在运行期决定的；
- 静态绑定：绑定的是静态类型，所对应的函数或属性依赖于对象的静态类型，发生在编译期；
- 动态绑定：绑定的是动态类型，所对应的函数或属性依赖于对象的动态类型，发生在运行期；

从上面的定义也可以看出，非虚函数一般都是静态绑定，而虚函数都是动态绑定（如此才可实现多态性）。**需要说明的是虚函数才具有动态绑定** ，举个例子：

```C++
#include <iostream>
using namespace std;

class A
{
public:
	/*virtual*/ void func() { std::cout << "A::func()\n"; }
};
class B : public A
{
public:
	void func() { std::cout << "B::func()\n"; }
};
class C : public A
{
public:
	void func() { std::cout << "C::func()\n"; }
};
int main()
{
	C* pc = new C(); //pc的静态类型是它声明的类型C*，动态类型也是C*；
	B* pb = new B(); //pb的静态类型和动态类型也都是B*；
	A* pa = pc;      //pa的静态类型是它声明的类型A*，动态类型是pa所指向的对象pc的类型C*；
	pa = pb;         //pa的动态类型可以更改，现在它的动态类型是B*，但其静态类型仍是声明时候的A*；
	C *pnull = NULL; //pnull的静态类型是它声明的类型C*,没有动态类型，因为它指向了NULL；
    
    pa->func();      //A::func() pa的静态类型永远都是A*，不管其指向的是哪个子类，都是直接调用A::func()；
	pc->func();      //C::func() pc的动、静态类型都是C*，因此调用C::func()；
	pnull->func();   //C::func() 不用奇怪为什么空指针也可以调用函数，因为这在编译期就确定了，和指针空不空没关系；
	return 0;
}
```

如果将A类中的virtual注释去掉，则运行结果是：

```cpp
pa->func();      //B::func() 因为有了virtual虚函数特性，pa的动态类型指向B*，因此先在B中查找，找到后直接调用；
pc->func();      //C::func() pc的动、静态类型都是C*，因此也是先在C中查找；
pnull->func();   //空指针异常，因为是func是virtual函数，因此对func的调用只能等到运行期才能确定，然后才发现pnull是空指针；   
```

在上面的例子中，

- 如果基类A中的func不是virtual函数，那么不论pa、pb、pc指向哪个子类对象，对func的调用都是在定义pa、pb、pc时的静态类型决定，早已在编译期确定了。
- 同样的空指针也能够直接调用no-virtual函数而不报错（这也说明一定要做空指针检查啊！），因此静态绑定不能实现多态；
- 如果func是虚函数，那所有的调用都要等到运行时根据其指向对象的类型才能确定，比起静态绑定自然是要有性能损失的，但是却能实现多态特性；



### 引用是否能实现动态绑定，为什么可以实现？

其实就是父类指针指向子类对象，调用虚函数的时候，发生的动态绑定。

同理，使用父类对象的引用指向子类对象也是可以的

可以。

引用在创建的时候必须初始化，在访问虚函数时，编译器会根据其所绑定的对象类型决定要调用哪个函数。注意只能调用虚函数。



### 类如何实现只能静态分配和只能动态分配？

建立类的对象有两种方式：

① 静态建立，静态建立一个类对象，就是由编译器为对象在栈空间中分配内存；

② 动态建立，A *p = new A();动态建立一个类对象，就是使用new运算符为对象在堆空间中分配内存。这个过程分为两步，第一步执行operator new()函数，在堆中搜索一块内存并进行分配；第二步调用类构造函数构造对象；

因此**只能静态分配**的话，就是**把new，delete 运算符重载成 private 属性、**

**只能动态分配的话**，**把构造函数和析构函数设置成 protected 或者 private 属性**。当静态建立的时候，会检查类的析构函数的访问性，当不可访问的时候，就不会在栈空间上为其分配内存，因此，静态分配会失败。但是动态分配不用判断析构函数的可访问性，直接调用构造函数构建



### 类的静态成员与普通成员的区别是什么？

- 生命周期不同：静态成员从类被加载到类被卸载，而普通成员是从类的对象开始到对象结束
- 共享方式：静态成员是属于类的，全类共享。普通成员是每个对象共享
- 定义位置：静态成员存储在静态全局区，而普通成员存储在栈或堆区
- 初始化位置：静态成员在类外初始化，普通成员在类内初始化



### 如何设计一个计算仅单个子类的对象个数？

设计一个类的 static 静态变量

- 在构造函数中 count++
- 在拷贝构造函数中 count++
- 在复制构造函数中 count++
- 在析构函数中 count--



### 成员初始化列表会在什么时候用到？它的调用过程是什么？

- 初始化一个引用成员变量时候
- 初始化一个 const 成员变量的时候
- 调用基类的构造函数，并且有参数的时候
- 调用一个成员类的构造函数，并且有参数



###  如何禁止程序自动生成拷贝构造函数？

1. 手动重写函数，并且设置为 private
2. 设置为 private 后，类内和 friend 函数也是可以调用的，可以定义一个基类，在基类中设置为 private，这样当派生类继承的时候，就不会自动生成该函数。并且由于基类中是私有的，派生类可以阻止编译器执行相关操作



### 友元函数和友元类的基本情况？

友元函数：在类外定义，不属于任何类，当在类中声明函数是友元函数后，可以访问和修改类的私有成员

```C++
#include <iostream>

using namespace std;

class A
{
public:
    friend void set_show(int x, A &a);      //该函数是友元函数的声明
private:
    int data;
};

void set_show(int x, A &a)  //友元函数定义，为了访问类A中的成员
{
    a.data = x;
    cout << a.data << endl;
}
int main(void)
{
    class A a;

    set_show(1, a);

    return 0;
}
```

友元类：友元类中的所有的成员函数都是另一个类的友元函数，可以访问类中的所有信息

```C++
#include <iostream>

using namespace std;

class A
{
public:
   friend class C;                         //这是友元类的声明
private:
   int data;
};

class C             //友元类定义，为了访问类A中的成员
{
public:
   void set_show(int x, A &a) { a.data = x; cout<<a.data<<endl;}
};

int main(void)
{
   class A a;
   class C c;

   c.set_show(1, a);

   return 0;
}
```

友元类的注意事项：

- 友元关系不能被继承
- 友元关系是单向的，若 B 是 A 的友元类，则A不一定是 B 的友元类
- 友元不具有传递性，若类 B 是类 A 的友元，类 C 是类 B 的友元，类 C 不一定是类 A 的友元





















## 内存

### 谈谈C++的内存对齐？

[博客（地址按字节寻址，移动一个字节加一）](https://blog.csdn.net/weixin_48896613/article/details/127371045)

- 内存对齐：在 C 语言中，结构体是一种复合数据类型，它的构成元素可以是基本数据类型（int、long、float等），也可以是复合数据类型（数组、结构体等）的数据单元。为了让 CPU 能够对变量进行快速访问，变量的起始地址应该具有某种特性，即 "对齐"。例如 4 字节的 int 型，它的起始地址应该位于 4 字节的边界上，也就是能被 4 整除。这样就称之为自然对齐，于是 CPU 可以一次取出数据
- C++ 内存对齐：用于三种数据类型：struct / class / union，对齐原则有四个
  1. 数据成员对齐规则： struct 或者 union 的数据成员，第一个数据成员放在 offset 为 0 的地方，以后每个数据成员存储的起始位置都要从该成员大小或者成员的子成员大小的整数倍开始
  2. struct 作为成员：如果一个结构里有某些结构体成员，则结构体成员要从其内部 “最宽基本类型成员” 的整数倍地址开始存储（struct A 里面有成员 struct B，B里的成员有 char，int， double等元素，那 B 应该从 8 的整数倍开始存储）
  3. 收尾工作：结构体的大小，也就是 sizeof 的结果，必须是其内部最大成员的 “最宽基本类型成员” 的整数倍。不足的要补齐
  4. sizeof(union) 以结构里面 size 最大的元素为 union 的 size，因为在某一时刻，union 只有一个成员真正的存储在该地址



### 为什么C++没有垃圾回收机制？

垃圾收集器：是一种动态存储分配器，它自动释放程序不再需要的已分配的块，这些块也被成为垃圾。在程序员看来，垃圾就是不再被引用的对象，自动回收垃圾的过程则称为垃圾收集。

- 首先，实现一个垃圾回收器会带来额外的空间和事件开销，需要开辟一定的空间保存指针的引用计数和对他们进行标记 mark，然后需要单独开辟一个线程在空闲的时候进行 free 操作
- 垃圾回收会使得 C++ 不适合进行很多底层操作



### 什么是内存泄漏？

内存泄露：简单的说就是申请了一块内存地址，但是用完之后没有释放掉

- new 和 malloc 申请资源使用后，没有使用 delete 和 free 释放
- 子类继承父类时，父类析构函数不是虚函数
- Windows 句柄资源使用后没有释放

后果：只发生一次小的内存泄漏可能不被注意，但泄露大量的内存程序将会出现各种症状；性能下降到内存逐渐用完，导致另一个程序失败

如何避免：

- 使用内存分配的函数，一旦使用完毕，要记得使用其对应的函数释放掉。有 new 就有 delete，有 malloc 就有 free，对象数组一定要用 delete []
- 一定要把基类的析构函数声明为 虚函数
- 使用智能指针



### C++ 的内存分区？

1. 栈区：存放函数的参数值和局部变量的值，由编译器自动分配和释放
2. 堆区：由程序员申请后使用，需要手动释放否则会造成内存泄漏。如果程序员没有手动释放，那么程序结束可能由操作系统回收
3. 全局/静态 存储区：存放全局变量和静态变量，初始化的全局变量和静态变量放在一块，未初始化的放在另一块
4. 常量区：存放常量字符串、常量变量等。程序启动时自动分配，程序结束时系统释放。
5. 程序代码区：存放程序的二进制代码，内存由系统管理



### 堆和栈的区别？

|                |             堆                                               |                    栈                                          |
| ---------------- | :----------------------------------------------------------- | :----------------------------------------------------------: |
| **管理方式**     | 堆中资源由程序员控制（容易产生memory leak）                  | 栈资源由编译器自动管理，无需手工控制                         |
| **内存管理机制** | 系统有一个记录空闲内存地址的链表，当系统收到程序申请时，遍历该链表，寻找第一个空间大于申请空间的堆结点，删 除空闲结点链表中的该结点，并将该结点空间分配给程序（大多数系统会在这块内存空间首地址记录本次分配的大小，这样delete才能正确释放本内存空间，另外系统会将多余的部分重新放入空闲链表中） | 只要栈的剩余空间大于所申请空间，系统为程序提供内存，否则报异常提示栈溢出。（这一块理解一下链表和队列的区别，不连续空间和连续空间的区别，应该就比较好理解这两种机制的区别了） |
| **空间大小**     | 堆向高地址扩展，是不连续的内存区域，大小可以灵活调整。 堆是不连续的内存区域（因为系统是用链表来存储空闲内存地址，自然不是连续的），堆大小受限于计算机系统中有效的虚拟内存（32bit 系统理论上是4G），所以堆的空间比较灵活，比较大 | 栈顶和栈底是之前预设好的，栈是向栈底扩展，大小固定，可以通过ulimit -a查看，由ulimit -s修改。 栈是一块连续的内存区域，大小是操作系统预定好的，windows下栈大小是2M（也有是1M，在 编译时确定，VC中可设置） |
| **碎片问题**     | 对于堆，频繁的new/delete会造成大量碎片，使程序效率降低       | 对于栈，它是有点类似于数据结构上的一个先进后出的栈，进出一一对应，不会产生碎片。（看到这里我突然明白了为什么面试官在问我堆和栈的区别之前先问了我栈和队列的区别） |
| **生长方向**     | 堆向上，向高地址方向增长。                                   | 栈向下，向低地址方向增长。                                   |
| **分配方式**     | 堆都是动态分配（没有静态分配的堆）                           | 栈有静态分配和动态分配，静态分配由编译器完成（如局部变量分配），动态分配由alloca函数分配，但栈的动态分配的资源由编译器进行释放，无需程序员实现。 |
| **分配效率**     | 堆的操作是由C/C++函数库提供的，在分配堆内存的时候需要一定的算法寻找合适大小的内存。并且获取堆的内容需要两次访问，第一次访问指针，第二次根据指针保存的地址访问内存，因此堆比较慢。 | 栈是其系统提供的数据结构，计算机在底层对栈提供支持，分配专门 寄存器存放栈地址，栈操作有专门指令。 |



### segment fault是什么错误？

通常是以下几个原因：

- 内存访问越界
- 多线程程序使用了线程不安全的函数
- 非法指针
- 堆栈溢出



### new/delete、malloc/free

- new/delete 是 C++ 操作符关键字，需要编译器支持， malloc 是 C/C++  标准库函数，需要头文件支持
- 使用 new 申请内存时，不用指定内存块的大小， 使用 malloc 申请内存时，需要显式的指出需要分配的内存大小
- new 分配失败时，会抛出 bac_alloc 异常，而 malloc 失败时会返回 NULL
- new 分配成功时会返回对象类型的指针，但是 malloc 成功时会返回 void，需要强转成 需要的类型
- new/delete 会调用对象的构造函数 和 析构函数，而 malloc/free 不会调用



### 既然有了malloc/free，C++中为什么还需要new/delete呢？直接用malloc/free不好吗？

在对结构体类等对象使用的时候，因为对象创建会调用构造函数，对象销毁会调用析构函数，而 malloc/free 是库函数，不会调用构造和析构函数，因此 new/delete 是必不可少的





### 被free回收的内存会立即返还给操作系统吗？

不是的，被 free 的内存会使用双链表保存起来，当用户下一次申请内存的时候，会尝试在链表中寻找合适的内存，这样就避免了频繁的系统调用



### C++中有几种 new

plain new，nothrow new, placement new



### delete p, delete [] p 的区别？

- delete 只会调用一次析构函数
- delete [] p 会调用数组中每个元素的析构函数
- delete [] 的时候，按数组中元素的逆序销毁



### 内存池？

内存池（Memory Pool） 是一种**内存分配**方式。通常我们习惯直接使用new、malloc 等申请内存，这样做的缺点在于：由于所申请内存块的大小不定，当频繁使用时会造成大量的内存碎片并进而降低性能。内存池则是在真正使用内存之前，先申请分配一定数量的、大小相等(一般情况下)的内存块留作备用。当有新的内存需求时，就从内存池中分出一部分内存块， 若内存块不够再继续申请新的内存。这样做的一个显著优点是尽量避免了内存碎片，使得内存分配效率得到提升。



### C++中类的数据成员和成员函数内存分布情况？

- 类的大小：
  - **非静态成员**的数据类型大小之和
  - 边缘对齐优化加入 padding：内存对齐另外分配的空间大小，类内的数据也是需要进行内存对齐操作的
  - 有虚函数的话，会在类对象插入vptr指针，加上指针大小
- 静态成员不占据类的空间，成员函数也不占据类的空间大小
- 当该类是某类的派生类，那么派生类继承的基类部分的数据成员也会存在在派生类中的空间中，也会对派生类进行扩展
- 一个类对象的地址就是类所包含的这一片内存空间的首地址，这个首地址也就对应具体某一个成员变量的地址
- 对象的大小和对象中数据成员的大小是一致的，成员函数不占用对象的内存。这是因为所有的函数都是存放在代码区的，不管是全局函数，还是成员函数。
- 静态成员函数的存放问题：静态成员函数与一般成员函数的唯一区别就是没有this指针，因此不能访问非静态数据成员。所有函数都存放在代码区，静态函数也不例外。所有有人一看到 static 这个单词就主观的认为是存放在全局数据区，那是不对的。



### 深拷贝和浅拷贝？

浅拷贝：浅拷贝只是拷贝一个指针，并没有开辟新的内存空间，拷贝的指针和原来的指针指向同一块地址，如果原来的指针所指向的资源释放了，那么再释放浅拷贝的指针的资源就会出错

在计算机中开辟了一块新的内存地址用于存放复制的对象。

深拷贝不仅拷贝值，还开辟出一块新的空间用来存放新的值，即使原先的对象被析构掉，释放内存了也不会影响到深拷贝得到的值。在自己实现拷贝赋值的时候，如果有指针变量的话是需要自己实现深拷贝的。



### 对象复用和零拷贝？

**对象复用**的本质是一种设计模式：Flyweight享元模式

通过把对象存储到“对象池”中实现对象的重复利用，可以避免多次创建重复对象的开销，节省系统资源

**零拷贝**：是一种避免 CPU 把数据从一块存储拷贝到另外一块存储的技术，可以减少数据拷贝和共享总线操作的次数

在 C++ 中，vector 的成员函数 **emplace_back** 很好的体现了零拷贝技术，跟 **push_back** 一样可以把元素车入到容器的尾部，区别在于：**使用push_back()函数需要调用拷贝构造函数和转移构造函数，而使用emplace_back()插入的元素原地构造，不需要触发拷贝构造和转移构造**，效率更高。





### 类如何实现只能静态分配？和只能动态分配？

建立类的对象有两种方式：

① 静态建立：静态建立一个类对象，就是由编译器为对象在栈空间中分配内存

② 动态建立：A *p = new A(); 动态建立一个类对象，就是使用new运算符为对象在堆空间中分配内存。这个过程分为两步，第一步执行operator new()函数，在堆中搜索一块内存并进行分配；第二步调用类构造函数构造对象

**只能动态分配**

类对象只能通过new运算符建立在堆空间中，不能静态分配，即不能直接调用类的构造函数

1.  private 构造函数（不可行），没法调用 构造函数
2. private 析构函数（无法实现继承），如果类的析构函数在类外部无法访问，则编译器拒绝在栈空间上为类对象分配内存。因此，可以将析构函数设为private，这样就无法在栈上建立类对象了。但是当作为基类让子类继承的时候，需要把析构函数设置为 virtual 函数，然后子类重写虚析构函数，但如果是 private 的话，子类是无法访问的。
3. 构造、析构函数设为 protected。将析构函数设为protected，类外无法访问protected成员，但是子类可以访问。

**只能静态分配**

只有使用 new 运算法，才会在堆上动态创建对象，于是，限制 new 运算符的使用即可。可以把 new 运算符设置为 私有



### 函数调用的过程

1. 第一个进栈的是（主函数中的） 调用处的下一条指令（即函数调用语句的下一条可执行语句） 的地址；

2. 然后是函数的各个参数，而在大多数C/C++编译器中，在函数调用的过程中，函数的参数是 由右向左入栈的；

3. 然后是函数内部的 局部变量（注意static变量是不入栈的）；

在函数调用结束（函数运行结束）后

1. 局部变量最先出栈

2. 然后是参数

3. 最后栈顶指针指向最开始存的指令地址，程序由该点继续运行。



### 谈谈智能指针?

智能指针是一个类，用来存储指向动态分配对象的指针，负责自动释放动态分配的对象，防止堆内存泄漏。动态分配的资源，交给一个类对象去管理，当类对象声明周期结束时，自动调用析构函数释放资源





## STL

### C++ 的 STL？

STL从广义来讲包括了三类：算法，容器和迭代器。

- 算法：包括排序，复制等常用算法，以及不同容器特定的算法
- 容器就是数据的存放形式，包括序列式容器和关联式容器，序列式容器是 list，vector，queue, deque 等，关联式容器就是 set，map 等
- 迭代器就是在不暴露容器内部结构的情况下对容器的遍历



### 什么是trivial destructor？

用户没有自定义 析构函数，是由系统自动生成的

对于trivial destructor，如果每次都进行调用，显然对效率是一种伤害



### 迭代器：++it、it++哪个好，为什么？

前置返回一个引用，后置返回一个对象

```C++
// ++i实现代码为：
int& operator++()
{

  *this += 1;
  return *this;

} 
```

前置不会产生临时对象，后置必须产生临时对象，临时对象会导致效率降低

```C++
//i++实现代码为：                 
int operator++(int)                 
{
int temp = *this;                   

   ++*this;                       

   return temp;                  
} 
```



### vector与list的区别与应用？怎么找某vector或者list的倒数第二个元素?

-  vector 可以实现随机访问，但是 list 只能从前向后遍历访问
- vector 的插入和删除操作会有内存拷贝，list 对数据插入和删除比较方便
- 从遍历上来说，vector 是双向的，list 是单向的
- vector 的迭代器在使用后就失效了，list 的迭代器在使用后还可以继续使用



vector 可以直接算出长度，根据下标访问，而 list 可以使用反向迭代器访问



### vector 为什么是两倍扩容？ 

size()函数返回的是已用空间大小，capacity()返回的是总空间大小

可以使用reserve(n)预先分配一块较大的指定大小的内存空间

因为扩容之后，需要把之前 vector 里的内容重新插入，采用成倍方式扩容，可以保证常数的时间复杂度，而增加指定大小的容量只能达到O(n)的时间复杂度



### Vector如何释放空间?

vector的内存占用空间只增不减，例如存放了 100 个元素，erase 99 个元素，只剩一个的时候，vector 仍然占用着 100 个元素的内存空间，只有在 vector 析构的时候才被回收

如果使用vector，可以用swap()来帮助释放多余内存或者清空全部内存。

```C++
int main() {
    vector<int> vec;
    for (int i = 0; i < 1000; i++) {
        vec.emplace_back(i);
    }
    cout << "capacity:" << vec.capacity() << " size:" << vec.size() << endl;	// capacity:1024 size:1000
    vector<int>().swap(vec);
    cout << "capacity:" << vec.capacity() << " size:" << vec.size() << endl;	// capacity:0 size:0
}
```



### 容器内部删除一个元素?

- 顺序容器（vector, deque）, erase 迭代器不仅使所指向被删除的迭代器失效，而且被删元素之后的所有迭代器失效（list 除外），所以不能使用 erase(it++)，但是erase 的返回值是下一个有效迭代器
- 关联容器（set, map），erase 迭代器只是被删除元素的迭代器失效，但是返回值是 void，所以要采用 erase(it++) 的方式删除迭代器



### STL迭代器如何实现？

迭代器是一种抽象的概念，通过迭代器可以在不了解容器内部原理的情况下遍历容器。此外，迭代器还是容器和算法的粘合剂

迭代器的作用就是提供一个遍历容器内部所有元素的接口，因此迭代器内部必须保存一个与容器相关的指针

常用的迭代器的相应类型有五种：`value type`, `difference type`, `pointer`, `reference`, `iterator catagoly`



### 迭代器失效？

迭代器之所以失效最大的原因是成为悬空指针了

**vector：** 

- 插入失效：
  - **扩容导致迭代器失效**：当前 vector 数组已经满了，在使用 insert(it) 插入的时候，会触发 vector 的自动扩容操作，在新的内存区域开辟两倍的大小空间，而原来的内存区域就被释放了，因此迭代器失效
  - **指向位置改变导致迭代器失效**：例如向当前下标为 1 的位置插入一个元素，插入之后的迭代器指向的是新元素，++之后指的是下标为 2 的元素，但是还是原来下标为 1 的那个数
- 删除失效：同样是位置变了，比如1 2 3 4 5，删除it指向2，删除后，变成1 3 4 5，此时删除后本来就指向了3，但是还++了就变成4了。

**list：**

list 底层是链表，插入时候不需要移动大量数据，其在插入的时候迭代器是不会失效的

删除操作时会使迭代器失效



### 红黑树概念？

是一个二叉排序树，若左子树不空，则左子树的所有节点均小于等于根节点，若右子树不空，则右子树的所有节点均大于等于根节点

- 树中所有节点非红即黑
  - 根节点必为黑节点
  - 红节点的子节点必为黑（黑节点子节点可为黑）
  - 从根到NULL的任何路径上黑结点数相同
  - 查找时间一定可以控制在O(logn)













## C++ 11 新特性

### C++ 11有哪些新特性？

- 智能指针
- auto 和 decltype 实现类型自动推导
- 基于范围的 for 循环 for(auto i : a)
- lambda 表达式
- 类和结构体的统一的列表初始化
- 右值引用和 move 语义
- nullptr 代替 NULL
- 关键字default和delete
- 移动构造和移动赋值



### auto 和 decltype 的区别

都可以进行类型的自动推导，但是 decltype 可以作为容器的参数类型，auto 不行

```C++
int main()
{
	map<string, string> m = { { "insert", "插入" }, { "sort", "排序" } };
	auto it = m.begin();
	//vector<auto it> v;//错误
	vector<decltype(it)> v;//正确
	return 0;
}
```



### 左值与右值？

左值：可以被引用的数据对象，包括变量，指针，引用，数组元素等

右值：字面常量，包含多项表达式以及返回值的函数

简单来说，左值有地址空间，可以使用取地址符取值，右值只有临时地址空间，不能用取地址符



### 左值引用和右值引用？

**下面是左值引用 `&`**

```C++
int main()
{
	// 以下的p、b、c、*p都是左值，都能被取地址
	int* p = new int(0);
	int b = 1;
	const int c = 2;
	// 以下几个是对上面左值的左值引用
	int*& rp = p;
	int& rb = b;
	const int& rc = c;
	int& pvalue = *p;
	return 0;
}
```

**下面是右值应用 `&&`**

```C++
int main()
{
	double x = 1.1, y = 2.2;
	// 以下几个都是常见的右值
	10; 
	x + y;
	fmin(x, y);
	// 以下几个都是对右值的右值引用
	int&& rr1 = 10;
	double&& rr2 = x + y;
	double&& rr3 = fmin(x, y);
	// 以下编译会报错：error C2106: “=”: 左操作数必须为左值
	//10 = 1; 
	//x + y = 1;
	//fmin(x, y) = 1;
	return 0;
}
```

给右值取别名后，会导致右值被存储到特定位置，且可以取到该位置的地址(可以理解为对右值取别名之后，这个别名就变为了左值)，也就是说例如：不能取字面量10的地址，但是rr1引用后，可以对rr1取地址，也可以修改rr1。如果不想rr1被修改，可以用const int&& rr1 去引用



`左值引用`：

1. 左值引用只能引用左值，不能引用右值。
2. 但是const左值引用既可引用左值，也可引用右值

```C++
int main()
{
	double x = 1.1, y = 2.2;
	10; 
	x + y;
	fmin(x, y);
	
	//引用前必须加上const， 否则会报错
	const int& r = 10;
	const double& r1 = x + y;
	const double& r2 = fmin(x, y);
	return 0;
}
```



`右值引用`：

3. 右值引用只能右值，不能引用左值。
4. 但是右值引用可以move以后的左值。

move() 就是把左值变成右值

```C++
int main()
{
	// 以下的p、b、c、*p都是左值
	int* p = new int(0);
	int b = 1;
	const int c = 2;
	
	//右值引用引用左值
	int* && rr1 = move(p);
	int && rr2 = move(*p);
	int && rr3 = move(b);
	const int && rr4 = move(c);
	return 0;
}
```



### NULL和nullptr区别?

NULL来自C语言，一般由宏定义实现，而 nullptr 则是C++11的新增关键字

C++ 中的 NULL 被定义成字面常量 0，这样会带来一些问题，因为 0 既可以指整形常量，又可以指指针常量，所以处于安全的角度，增加了 nullptr 代表空指针



###  lambda表达式？

语法格式：`[捕捉列表]（参数）mutable -> 返回值 （函数体）`

```C++
int main()
{
	auto add = [](int a, int b)->int{return a + b; };	
	//[](int a, int b){return a + b;};
	cout << add(1, 2) << endl;
	return 0;
}
```

通过捕捉列表交换两个变量的值:

- [var]：表示值传递方式捕捉变量var
- [=]：表示值传递方式捕获所有父作用域中的变量(成员函数中包括this)
- [&var]：表示引用传递捕捉变量var
- [&]：表示引用传递捕捉所有父作用域中的变量(成员函数中包括this)

```C++
int main()
{
	int a = 10, b = 20;
	auto swap = [&a, &b]()mutable
	{
		int c = a;
		a = b;
		b = c;
	};
	swap();
	cout << "a:" << a << " " << "b:" << b << endl;
	return 0;
}
```



### default 和 delete?

default：强制默认生成函数，例如已经提供了拷贝构造函数，编译器就不会自动生成默认拷贝构造函数了，可以使用 default 生成

delete：强制禁止生成函数



### 移动构造函数和移动赋值？

移动构造函数就是把原对象指的位置拷贝给新对象，并且把源对象的指向改为空

同理，移动赋值函数也是如此

**移动构造函数必须使用的是右值引用**

```C++
#include<iostream>
using namespace std;
 
class A{
public:
	A(){
		this->num = new int(10);
		cout << "构造函数" << endl;
	}
	A(A&x){
		this->num = new int(*x.num);
		cout << "拷贝构造函数" << endl;
	}
	A(A&&x){
		this->num = x.num;
		x.num = nullptr;
		cout << "移动构造函数" << endl;
	}
	~A(){
		cout << "析构函数" << endl;
	}
	int *num;
};
 
void test(){
	A a;
	A b=a;
	A c(move(a));
}
 
int main()
{
	test();
	system("pause");
	return 0;
}
```





## 智能指针

C++智能指针的本质就是避免悬空指针的产生



### 智能指针的原理？

智能指针其实是一个类，用来存储指向动态分配内存对象的指针，负责自动释放动态分配的对象，防止内存泄漏。动态分配的资源，交给一个类对象去管理，当类对象的生命周期结束时，自动调用析构函数释放动态分配的资源

智能指针基本的函数有，一个私有的成员变量，构造函数，析构函数以及运算符重载 `*` 和 `->`

```C++
template<class T>
class sample_ptr{
public:
    sample_ptr(T* ptr):m_ptr(ptr){};
    ~sample_ptr(){
        if(m_ptr != nullptr){
            delete m_ptr;
            m_ptr = nullptr;
        }
    }
	
    //定义拷贝构造函数
    //重载 = 运算符
    
    //重载 * 运算符
    T& operator* (){
        return *m_ptr;
    }

    //重载 -> 运算符
    T* operator-> (){
        return m_ptr;
    }

private:
    T* m_ptr;
};

int main(){
    sample_ptr<int> ptr(new int(1));
    return 0;
}
```





### 常用的智能指针及实现？

**auto_ptr：**采用的是移动构造函数的思想，当调用拷贝构造函数的时候，新对象指向原对象的内存地址，而原对象会被设置为 nullptr

**unique_ptr：** 直接把拷贝构造函数和赋值重载函数禁掉，不让其拷贝和赋值

**shared_ptr：** 允许多个指针指向同一块内存资源，采用了引用计数

- shared_ptr 在内部会维护一份引用计数，用来记录该资源被几个对象共享
- 当一个 shared_ptr 对象被销毁时，析构函数会把该计数减一
- 如果引用计数不是 0，说明还有其他对象在用，就不会释放该资源
- 当引用计数减为 0 时，则表示是最后一个对象，要把资源释放掉

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230422204502.png)

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230422204535.png)

`ptr2 = ptr1`赋值构造函数的三种情况：

- ptr1 = ptr1，自己给自己赋值，不处理
- ptr1 和 ptr2 指向同一空间，则不处理
- ptr1 和 ptr2 指向不同空间，处理过程是，首先 ptr2 需要根据引用计数来判断是否其原来的释放资源，然后再让 ptr2 指向 ptr1 指向的资源，引用加一
- 由于所有线程都可对引用计数修改，因此需要加锁

```C++
template<class T>
class shared_ptr{
public:
    //删除默认构造函数
    shared_ptr() = delete;
    
    //初始化构造函数
    shared_ptr(T* ptr) : m_ptr(ptr){
        m_ptrcount = new int(1);
        mt = new mutex;
    }
    //拷贝构造函数
    shared_ptr(shared_ptr<T>& sp): m_ptr(sp.m_ptr), m_ptrcount(sp.m_ptrcount), mt(sp.mt) {
        addCount();
    }

    //重载 = 运算符
    // ptr1 = ptr1
    // ptr2 = ptr1, 两者指向同一内存空间
    // ptr2 = ptr1，两者指向不同内存空间
    shared_ptr<T>& operator=(const shared_ptr<T>& sp){
        //如果不同内存空间，先把 ptr2 释放掉
        if(m_ptr != sp.m_ptr){
            release();
            m_ptr = sp.m_ptr;
            m_ptrcount = sp.m_ptrcount;
            mt = sp.mt;
            addCount();
        }
        return *this;
    }

    //析构函数,需要判断是否释放
    ~shared_ptr(){
        release();
    }

    //增加引用计数
    void addCount(){
        mt->lock;
        (*m_ptrcount)++;
        mt->unlock;
    }

    //释放函数，判断引用计数
    void release(){
        mt->lock;
        (*m_ptrcount)--;
        mt->unlock;

        if((*m_ptrcount) == 0){
            delete m_ptr;
            delete m_ptrcount;
            delete mt;
            m_ptr = nullptr;
            m_ptrcount = nullptr;
            mt = nullptr;
        }
    }

    //查看引用计数
    int& use_count(){
        return *m_ptrcount;
    }

    //重载 * 运算符
    T& operator* (){
        return *m_ptr;
    }

    //重载 -> 运算符
    T* operator-> (){
        return m_ptr;
    }

private:
    T* m_ptr;   //动态指针
    int* m_ptrcount;    //引用计数的指针
    mutex* mt;
};
```

**weak_ptr：** weak_ptr类的对象它可以指向shared_ptr，并且不会改变shared_ptr的引用计数。一旦最后一个shared_ptr被销毁时，对象就会被释放

weak_ptr对象指向shared_ptr对象时，不会增加shared_ptr中的引用计数，因此当node1销毁掉时，则node1指向的空间就会被销毁掉，node2类似，所以weak_ptr指针可以很好解决循环引用的问题





### shared_ptr的循环引用?

假设要使用定义一个双向链表，如果想要让创建出来的链表的节点都定义成shared_ptr智能指针，那么也需要将节点内的 _pre 和 _next 都定义成shared_ptr的智能指针。如果定义成普通指针，那么就不能赋值给shared_ptr的智能指针

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230422211429.png)

当其中两个节点互相引用的时候，就会出现循环引用的现象

- 当创建出node1和node2智能指针对象时，引用计数都是1
- 当node1的next指向node2所指向的资源时，node2的引用计数就+1，变成2，node2的pre指向noede1所指向的资源时，node1的引用计数+1，变成2
- 当这两个智能指针使用完后，调用析构函数，引用计数都-1，都变成1，由于引用计数不为0，所以node1和node2所指向的对象不会被释放
- 当node1所指向的资源释放需要当node2中的_prev被销毁，就需要node2资源的释放，node2所指向的资源释放就需要当node1中的_next被销毁，就需要node1资源的释放。因此node1和node2都有对方的“把柄”，这两个就造成循环引用现象，最终这node1和node2资源就不会进行释放。
  









## 多线程

## 模板

### 为什么模板类一般都是放在一个h文件中？

一个编译单元是 .cpp 文件和他包含的所有的 .h 文件，.h 文件中的代码会被扩展到 .cpp 文件里面，然后在编译过程中生成 .obj 的目标文件，当所有的 cpp 文件编译完成后，再由连接器连接成一个 .exe 文件

对于正常的函数来说，声明和实现是分开的，那么当在 main 中调用的时候，由于包含了 .h 文件，仅仅只是知道了其函数的声明，具体的实现会在其生成的 .obj 文件中找，找到地址后完成调用

但是对于模板类，如果声明和实现分开的话，由于其只有在使用的时候才会实例化出来，所以 .cpp 文件编译出来的 .obj 文件中是不会有模板类的实例化二进制代码，仅仅只依靠 .h 中的声明是没有办法的，于是会产生错误

如果声明和实现都在 .h 文件中，那么当主函数使用的时候，会从 .h 文件里找到其实现，从而实例化



### 模板会写吗？写一个比较大小的模板函数

```C++
#include<iostream>
using namespace std;
template<class A, class B>
A Max(A a, B b){
    return a < b ? b : a;
}

int main(){
    cout << Max(5, 'a') << endl;
    return 0;
}
```









## 编译和链接

### C++从代码到可执行二进制程序的流程

C++从源文件到可执行文件一共有四个步骤，**预编译、编译、汇编、链接**

**预编译：**将头文件、宏进行展开

1. 删除所有的 #define，并展开所有的宏定义
2. 删除所有的条件预编译指令，#if，#ifdef
3. 处理所有的 include 预编译指令，把被包含的文件插入到预编译指令的位置
4. 过滤所有的注释
5. 添加行号和文件名标识

**编译：**把预编译生成的 .i 或者 .ii 文件，进行一系列的 **词法分析、语法分析、语义分析以及优化** 后，生成相应的汇编代码文件

1. 词法分析：利用类似于“有限状态机”的算法，将源代码程序输入到扫描机中，将其中的字符序列分 割成一系列的记号。
2. 语法分析：语法分析器对由扫描器产生的记号，进行语法分析，产生语法树。由语法分析器输出的 语法树是一种以表达式为节点的树。
3. 语义分析：语法分析器只是完成了对表达式语法层面的分析，语义分析器则对表达式是否有意义进 行判断，其分析的语义是静态语义——在编译期能分期的语义，相对应的动态语义是在运行期才能确定 的语义。
4. 优化：源代码级别的一个优化过程。
5. 目标代码生成：由代码生成器将中间代码转换成目标机器代码，生成一系列的代码序列——汇编语言 表示。
6. 目标代码优化：目标代码优化器对上述的目标机器代码进行优化：寻找合适的寻址方式、使用位移 来替代乘法运算、删除多余的指令等。 

**汇编：**把编译生成的汇编代码转换成机器可以执行的指令。汇编之后，产生目标文件 xxx.o(Windows 下)、xxx.obj(Linux下)



**链接：**把不同源文件产生的目标文件进行链接，从而形成一个可执行程序。链接分为静态链接和动态链接

静态链接：在链接的时候就把需要调用的函数链接到了可执行文件中。生成的静态链接库，Windows下为 .lib，Linux 下为 .a

- 优点是，运行速度快，不依赖动态链接库
- 缺点是，空间浪费，更新代码困难

动态链接：在链接的时候，没有把需要的函数链接到可执行文件，而是在执行的过程中，再根据可执行文件中函数的重定位信息去找要链接的函数。生成的动态链接库在 Windows 下是 .dll，在 Linux 下是 .so

- 优点是，更新方便，只需要替换原来的目标文件。动态编译，加快了编译速度，节省了系统资源
- 缺点是，性能损耗，每次执行都要链接。如果计算机上没有安装相应的动态库，那可执行文件就不能运行



### 什么是 GCC，工作原理是什么？？

gcc 全称是 GNU **Compiler Collection** ，它是能够编译多种语言的编译器





### 写个函数在 main 函数前面执行？

全局变量的构造函数会在 main 函数之前执行

```C++
class App{
public:
    App(){
        cout << "First" << endl;
    }
};

App a;

int main(){
    cout << "Second" << endl;
    return 0;
}
```



## 其他

### 在main执行之前和之后执行的代码可能是什么

**main函数执行之前**，主要就是初始化系统相关资源

- 设置栈指针
- 初始化静态变量和全局变量，`.data`段的内容
- 将未初始化的全局变量赋初值，`.bss`段的内容
- 全局对象初始化，在`main`之前调用构造函数
- 将main函数的参数`argc`，`argv`等传递给`main`函数，然后才真正运行`main`函数



**main函数执行之后**：

- 全局对象的析构函数会在main函数之后执行；
- 可以用 **`atexit`** 注册一个函数，它会在main 之后执行



### strlen和sizeof区别？

- sizeof 是运算符，并不是函数，结果在编译时得到而不是运行中得到。strlen 是字符处理的库函数
- sizeof 参数可以使任何数据的类型或者数据。strlen 参数只能是字符指针或字符串
- sizeof 在编译时确定，所以不能用来动态分配存储空间大小



### C++和C语言的区别?

C++ 的头文件和 C 语言的头文件不一样

C++ 中有字符串类，而 C 语言没有，需要依靠字符数组处理

C++ new / delete 取代了 C 语言中的 malloc / free

C++ 允许函数重载，而 C 语言不行

C++ 有引用，而 C 语言没有

C++ 增加了一些关键字，如：bool、using、dynamic_cast、namespace等



### C++函数调用的压栈过程 ？

1. 从栈空间分配存储空间
2. 然后返回值压入栈中，参数列表从右向左依次入栈
3. 从实参的存储空间复制值到形参栈空间
4. 进行运算

形参在函数未调用之前都是没有分配存储空间的，在函数调用结束后，形参弹出栈空间，清除形参空间





### 怎样判断两个浮点数是否相等？

对两个浮点数判断大小和是否相等不能直接用==来判断，会出错！

对于两个浮点数比较只能通过相减并与预先设定的精度比较，记得要取绝对值！浮点数与0的比较也应该注意。与浮点数的表示方式有关



### C++中的指针参数传递和引用参数传递有什么区别？底层原理你知道吗？

**指针参数传递**本质上是值传递，它所传递的是一个地址值。

在函数调用的时候，形参作为被调函数的局部变量进行处理，会在栈中开辟空间来存放实参的值，这里局部变量形参的值就是指针中存放的地址



**引用参数传递** 时候，形参也是作为局部变量在栈中开辟地址内存空间，存放的是实参中传进来的变量的地址。函数中对形参的任何操作都被处理成间接寻址，通过栈中存放的地址访问实参变量



### 函数指针？

函数指针指向的是一个函数，一个函数是由其返回值以及参数列表决定的，和函数名称没有关系，因此类似

```C++
// 函数指针
int (* p)(int a, int& b);
```



### 你知道回调函数吗？它的作用？

当某件事发生的时候，程序会自动调用定义的一段函数

回调函数相当于一个中断处理函数，在一定条件下自动调用，只要把函数指针传递过去就会自动调用





### 说一下你理解的 ifdef endif代表着什么？

在一个大工程里，可能会有很多文件同时包含某个头文件，当这些文件被编译的时候，通过 ifdef 和 endif 来防止头文件重定义



### C++中标准库是什么？

标准库可分为两部分：

标准函数库：包含了各种标准函数，例如输入输出，字符串处理函数等

标准类库：I/O 类，String 类，STL容器类等













# 操作系统

## 内存管理

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230330143244.png)

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230330143328.png)

- 代码段：包括可执行的二进制代码
- 数据段：包括已初始化的全局变量和静态变量
- BSS段：包括未初始化的全局变量和静态变量
- 堆：包括动态分配的内存，从低地址向上增长
- 文件映射段：包括动态库，共享内存等
- 栈：包括局部变量和函数调用的上下文等



### 说一下你理解中的内存？他有什么作用呢？

内存是用来存放数据的硬件，程序执行前需要把数据先放到内存上才能被 CPU 处理







### 虚拟技术你了解吗？

虚拟技术把一个物理实体转换为多个逻辑实体。虚拟技术分成两种：

- 时分复用技术
- 空分复用技术

**多进程与多线程：**多个进程能在同一个处理器上并发执行使用了时分复用技术，采用算法让每个进程轮流的使用 CPU

**虚拟内存技术：** 使用了空分复用技术，把物理内存抽象成了地址空间，每个进程都有自己的虚拟地址空间，然后把虚拟地址空间的页和物理地址空间的页进行映射。地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中



### 操作系统在对内存进行管理的时候需要做些什么?

- 操作系统负责内存空间的分配与回收。
- 操作系统需要提供某种技术从逻辑上对内存空间进行扩充。
- 操作系统需要提供地址转换功能，负责程序的逻辑地址与物理地址的转换。
- 操作系统需要提供内存保护功能。保证各进程在各自存储空间内运行，互不干扰







###  malloc 是如何分配内存的？

malloc 申请内存的时候，会有两种方式向操作系统申请内存

1. 通过 brk() 系统调用从堆分配内存
2. 通过 mmap() 系统调用在文件映射区分配内存

一般情况下，当申请的内存小于 128KB，则通过 brk() 申请内存，大于 128KB，通过 mmap() 申请内存



###  malloc() 分配的是物理内存吗？

不是的，malloc 首先分配的是虚拟内存

如果分配的虚拟内存没有被访问的情况下，是不会映射到物理内存的

当分配的虚拟内存被访问时，通过查找页表，发现虚拟内存对应的页不在物理内存中，就会发生缺页中断，然后操作系统才会建立虚拟内存和物理内存之间的映射关系



### malloc(1) 会分配多大的虚拟内存？

malloc() 在分配内存的时候，并不是老老实实按用户预期申请的字节数来分配内存空间大小，而是**会预分配更大的空间作为内存池**。



### free 释放内存，会归还给操作系统吗？

- malloc 通过 **brk()** 方式申请的内存，free 释放内存的时候，**并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用**；
- malloc 通过 **mmap()** 方式申请的内存，free 释放内存的时候，**会把内存归还给操作系统，内存得到真正的释放**。





### 为什么不全部使用 mmap 来分配内存？

- 向操作系统申请内存需要通过系统调用，执行系统调用需要切换到内核态，执行完后再切换回用户态，开销比较大

- 因为通过 mmap() 方式申请的内存，free 之后会立刻返回给操作系统，那么每次第一次访问的时候，都会缺页中断

使用 brk() 在堆空间申请内存可以预分配更大的内存作为内存池，当内存释放的时候，会缓存在内存池里。下次申请的话，直接从内存池取出，可能当前的虚拟内存之前已经和物理内存建立映射关系，减少缺页中断次数



### 既然 brk 那么牛逼，为什么不全部使用 brk 来分配？

free 不回收的话，会产生较多的内部碎片





###  free() 函数只传入一个内存地址，为什么能知道要释放多大的内存？

malloc 返回给用户态的内存起始地址比进程的堆空间起始地址多了 16 字节

多出来的 16 字节就是保存了该内存块的描述信息，比如有该内存块的大小。



### 虚拟内存有什么作用？

1. 虚拟内存可以使进程的运行内存超过物理内存，因为程序运行符合局部性原理，CPU访问内存时有明显的重复性，对于那些没有经常被用到的内存，可以把它换出物理内存之外，例如硬盘的 Swap 区
2. 由于每个进程都有自己的页表，所以每个进程之间的虚拟内存是相互独立的，进程没法访问别的进程的页表，解决了多进程之间地址冲突的问题
3. 页表里页表项除了物理地址之外，还有一些标记属性的比特，控制一个页的读写权限，改页是否存在等。在访问内存的时候，提供了更好的安全性





### 内存回收

如果没有空闲的物理内存，那么内核就会开始进行**回收内存**的工作，回收的方式主要是两种：直接内存回收和后台内存回收。

- **后台内存回收**（kswapd）：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程**异步**的，不会阻塞进程的执行。
- **直接内存回收**（direct reclaim）：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是**同步**的，会阻塞进程的执行。

如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会放最后的大招了 ——**触发 OOM （Out of Memory）机制**。

OOM Killer 机制会根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，如果物理内存依然不足，OOM Killer 会继续杀死占用物理内存较高的进程，直到释放足够的内存位置



### 哪些内存可以被回收？

可被回收的内存类型有文件页和匿名页：

- 文件页的回收：对于干净页是直接释放内存，这个操作不会影响性能，而对于脏页会先写回到磁盘再释放内存，这个操作会发生磁盘 I/O 的，这个操作是会影响系统性能的。
- 匿名页的回收：如果开启了 Swap 机制，那么 Swap 机制会将不常访问的匿名页换出到磁盘中，下次访问时，再从磁盘换入到内存中，这个操作是会影响系统性能的。



### 针对回收内存导致的性能影响，常见的解决方式。

- 设置 /proc/sys/vm/swappiness，调整文件页和匿名页的回收倾向，尽量倾向于回收文件页；
- 设置 /proc/sys/vm/min_free_kbytes，调整 kswapd 内核线程异步回收内存的时机；



### 在 4GB 物理内存的机器上，申请 8G 内存会怎么样？

- 在 32 位操作系统，因为进程理论上最大能申请 3 GB 大小的虚拟内存，所以直接申请 8G 内存，会申请失败。
- 在 64位 位操作系统，因为进程理论上最大能申请 128 TB 大小的虚拟内存，即使物理内存只有 4GB，申请 8G 内存也是没问题，因为申请的内存是虚拟内存。如果这块虚拟内存被访问了，要看系统有没有 Swap 分区：
  - 如果没有 Swap 分区，因为物理空间不够，进程会被操作系统杀掉，原因是 OOM（内存溢出）；
  - 如果有 Swap 分区，即使物理内存只有 4GB，程序也能正常使用 8GB 的内存，进程可以正常运行；





### 传统的 LRU 算法法无法避免的两个问题？

- 预读失效导致缓存命中率下降；预读失效是指，当从磁盘读取数据到内存的时候，例如读取 0-2KB 的内容，由于操作系统分页，所以需要把 0-4KB 整页读进去，同时因为程序的局部性原理，可能还需要后面的内容，因此还把后面的几页也一起读进来。但是这些数据没有用到，占据了空间。
- 缓存污染导致缓存命中率下降；当批量读取数据的时候，只要数据被访问一次，就将数据加入到活跃 LRU 链表头部（或者 young 区域），但是后续可能再也用不到了，会造成缓存污染



为了避免「预读失效」造成的影响，Linux 和 MySQL 对传统的 LRU 链表做了改进：（相当于给预读的数据留了缓冲区）

- Linux 操作系统实现两个了 LRU 链表：**活跃 LRU 链表（active list）和非活跃 LRU 链表（inactive list）**。
- MySQL Innodb 存储引擎是在一个 LRU 链表上划分来 2 个区域：**young 区域 和 old 区域**。



为了避免「缓存污染」造成的影响，Linux 操作系统和 MySQL Innodb 存储引擎分别提高了升级为热点数据的门槛：（提高加入 active 链表的门槛）

- Linux 操作系统：在内存页被访问**第二次**的时候，才将页从 inactive list 升级到 active list 里。
- MySQL Innodb：在内存页被访问第二次的时候，并不会马上将该页从 old 区域升级到 young 区域，因为还要进行停留在 old 区域的时间判断：
  - 如果第二次的访问时间与第一次访问的时间**在 1 秒内**（默认值），那么该页就**不会**被从 old 区域升级到 young 区域；
  - 如果第二次的访问时间与第一次访问的时间**超过 1 秒**，那么该页就**会**从 old 区域升级到 young 区域；



### 动态分区分配算法有哪几种？可以分别说说吗？

1. **首次适应算法：** 每次都从低地址开始查找，找到第一个能满足大小的空闲分区
2. **最佳适应算法：** 为了保证大进程有连续的空间，优先使用更小的空闲区
3. **最坏适应算法：** 为了解决小的内存碎片，每次分配时优先使用较大的空闲区
4. **邻近适应算法：** 为了解决每次从低地址区开始查找，低地址出现很多小的空闲分区，每次从上次结束的位置开始向后检索



### 内存覆盖，内存交换是什么？有什么特点？

覆盖和交换技术是在多程序环境中扩展内存的两种方法.

覆盖技术主要用于早期操作系统，而交换技术在现代操作系统中仍然使用

**内存覆盖**： 早期的操作系统中，把用户空间分成为一个固定区和若干个覆盖区，程序的数据经常活跃的部分放在固定区，其他部分按照调用关系分段，覆盖区存放即将要访问的段，其他的段放在磁盘中，在需要调用的时候，放到覆盖区

**内存交换**： 内存空间紧张的时候，把内存中某些进程暂时换出到外存（swap?），把外存中已经具备运行条件的进程换入内存





### 什么是快表？和cache有什么区别？

**作用不同**： 

- 快表主要用于虚拟地址到物理地址的转换，它是存储在处理器中的一种小型高速缓存，用于存储最近使用的虚拟地址和对应的物理地址。
- Cache 则是用于提高存储器访问速度的一种存储技术，它将数据存储在距离处理器更近的高速缓存中，使得处理器可以更快地访问数据。

**存储的内容不同**：

- 快表存储的是虚拟地址和物理地址之间的映射关系，即页表
- Cache 存储的是数据

**存储器的位置不同**：

- 快表通常存储在处理器的芯片内部，因此访问速度非常快
- Cache 通常位于处理器和主存之间，访问速度比快表略慢



### 页面置换算法？

1. 最佳置换算法（OPT）：每次选择淘汰的页面将是以后永不使用，或者在最长时间内不再被访问的页面，这样可以保证最低的缺页率。但是无法提前预判页面访问序列。所以，最佳置换算法是无法实现的
2. 先进先出置换算法（FIFO）：每次选择淘汰的页面是最早进入内存的页面
3. 最近最久未使用置换算法（LRU）：每次淘汰的页面是最近最久未使用的页面
4. 时钟置换算法（CLOCK）：循环扫描各页面 第一轮淘汰访问位=0的，并将扫描过的页面访问位改为1。若第-轮没选中，则进行第二轮扫描
5. 改进的时钟置换算法：加入了修改位







## 进程与线程

### 系统并发和并行，分得清吗？

并行指的是同时运行多个程序，需要硬件的支持，包括多核处理器，多流水线，分布式计算系统等

并发是每个程序执行一段时间，宏观上看相当于是并行执行



### 进程、线程和协程的区别和联系?

|          | 进程                                                         | 线程                                               | 协程                                                         |
| -------- | ------------------------------------------------------------ | -------------------------------------------------- | ------------------------------------------------------------ |
| 定义     | 资源分配和拥有的基本单位                                     | 程序执行的基本单位                                 | 用户态的轻量级线程，线程内部调度的基本单位                   |
| 切换情况 | 进程CPU环境(栈、寄存器、页表和文件句柄等)的保存以及新调度的进程CPU环境的设置 | 保存和设置程序计数器、少量寄存器和栈的内容         | 先将寄存器上下文和栈保存，等切换回来的时候再进行恢复         |
| 切换者   | 操作系统                                                     | 操作系统                                           | 用户                                                         |
| 切换过程 | 用户态->内核态->用户态                                       | 用户态->内核态->用户态                             | 用户态(没有陷入内核)                                         |
| 调用栈   | 内核栈                                                       | 内核栈                                             | 用户栈                                                       |
| 拥有资源 | CPU资源、内存资源、文件资源和句柄等                          | 程序计数器、寄存器、栈和状态字                     | 拥有自己的寄存器上下文和栈                                   |
| 并发性   | 不同进程之间切换实现并发，各自占有CPU实现并行                | 一个进程内部的多个线程并发执行                     | 同一时间只能执行一个协程，而其他协程处于休眠状态，适合对任务进行分时处理 |
| 系统开销 | 切换虚拟地址空间，切换内核栈和硬件上下文，CPU高速缓存失效、页表切换，开销很大 | 切换时只需保存和设置少量寄存器内容，因此开销很小   | 直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快 |
| 通信方面 | 进程间通信需要借助操作系统                                   | 线程间可以直接读写进程数据段(如全局变量)来进行通信 | 共享内存、消息队列                                           |

1、进程是资源调度的基本单位，运行一个可执行程序会创建一个或多个进程，进程就是运行起来的可执行程序

2、线程是程序执行的基本单位，是轻量级的进程。每个进程中都有唯一的主线程，且只能有一个，主线程和进程是相互依存的关系，主线程结束进程也会结束。

3、协程是用户态的轻量级线程，线程内部调度的基本单位



### **线程和进程的区别？**

**调度：**进程是资源分配的基本单位，而线程是CPU调度的基本单位

**并发性**：多个进程可以并发，一个进程内多个线程可以并发

**拥有资源**：进程拥有完整的资源，而线程共享进程内的代码段、数据段、打开的文件等资源，拥有自己独立的寄存器和栈

**系统开销**：进程的创建和销毁需要处理task_struct结构，而线程创建销毁只需要处理 PC 值，通用寄存器值，线程栈等，开销较小，速度快



### 怎么回收线程？有哪几种方法？

- **等待线程结束**： 主线程调用 pthread_join ，等待子线程退出并回收资源，调用pthread_join的线程会被阻塞
- **结束线程：** 子线程执行 pthread_exit，用来结束当前线程并通过retval传递返回值，返回值可通过pthread_join获得
- **分离线程：** 主线程，子线程都可调用 pthread_detach(pthread_t tid) ，调用后和主线程分离，子线程结束时自己立即回收资源

pthread_join(1,NULL)  相当于是个线程回收函数，如果子线程没结束就等待其结束，然后回收资源，如果子线程已经结束，直接回收资源

- 代码中如果没有pthread_join主线程会很快结束从而使整个进程结束， 从而使创建的线程没有机会开始执行就结束了。 加入pthread_join后，主线程会一直等待直到等待的线程结束自己才结束， 使创建的线程有机会执行

```Shell
# 主要区别就是 pthread_exit 只能子线程自己调用， pthread_cancel 可以是别的线程调用
int pthread_cancel(pthread_t thread);
void pthread_exit(void *retval);
```







### 一个进程可以创建多少线程，和什么有关？

- **进程的虚拟内存空间上限**，因为创建一个线程，操作系统需要为其分配一个栈空间，如果线程数量越多，所需的栈空间就要越大，那么虚拟内存就会占用的越多
- **系统参数限制**，虽然 Linux 并没有内核参数来控制单个进程创建的最大线程个数，但是有系统级别的参数来控制整个系统的最大线程个数

过多的线程将会导致大量的时间浪费在线程切换上，给程序运行效率带来负面影响，无用线程要及时销毁



### 用户线程和内核线程

**用户线程**：在用户空间实现的线程，不是由内核管理的线程，由用户态的线程库来完成线程的管理；那么**线程控制块（\*Thread Control Block, TCB\*）** 也是在库里面来实现的，对于操作系统而言是看不到这个 TCB 的，它只能看到整个进程的 PCB。所以，**用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。**

优点：

- 每个进程都需要有它私有的线程控制块（TCB）列表，用来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统；
- 用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快

缺点：

- 由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了
- 当一个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的
- 由于时间片分配给进程，在多线程执行时，每个线程得到的时间片较少，执行会比较慢



**内核线程**：在内核中实现的线程，是由内核管理的线程；**线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。**

优点：

- 在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行
- 分配给线程，多线程的进程获得更多的 CPU 运行时间

缺点：

- 在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息，如 PCB 和 TCB
- 线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大



**轻量级进程**：是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持，而且 LWP 是由内核管理并像普通进程一样被调度



### 进程调度算法你了解多少？

非抢占式：只要得到 CPU ，一直执行完之后才执行别的作业

抢占式：通过调度算法，如果被选中了，不断 CPU 是否在执行别的作业，直接抢占

1. 先来先服务（FCFS）：非抢占式调度算法，按照请求的顺序进行调度。有利于长作业，但不利于短作业

2. 短作业优先（SJF）：非抢占式的调度算法，按估计运行时间最短的顺序进行调度。有利于短作业，但不利于长作业

3. 高响应比优先调度算法：**每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行**，「响应比优先级」的计算公式：`优先权=（等待时间 + 要求服务时间）/ 要求服务时间`。因为不知道一个进程要求服务的时间，所以，高响应比优先调度算法是「理想型」的调度算法，现实中是实现不了的

4. 时间片轮转调度算法：将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

5. 优先级调度：为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

6. 多级反馈队列：

   - 设置了多个队列，赋予每个队列不同的优先级，每个**队列优先级从高到低**，同时**优先级越高时间片越短**；

   - 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；

   - 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；

     ![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230320230734.png)








### Linux下进程间通信方式？

- 管道：管道是一种半双工的通信方式，数据只能单向流动
  - 匿名管道：没有名称，就是 Linux 里面的 `|` ，只能在具有血缘关系的进程之间使用
  - 命名管道：可以不用在父子进程之间的管道进行通信
- 消息队列：是消息的链表，存放在内核中并由消息队列标识符标识，解决了管道传递的信息少，只能承载无格式数据流的缺点
- 共享内存：映射一段能够被几个进程访问的内存，针对进程间通信效率低而设计的，往往和信号量配合来使用
- 信号：用来通知接受进程某个事件的发生，例如 `Ctrl + C ` 就是 `SIGINT` 信号，`Ctrl + Z` 就是 `SIGTSTP` 信号。
- 信号量：它是一个计数器，可以用来控制多个进程对共享资源的访问。经常作为一种锁机制，实现进程、线程的临界区的同步和互斥访问
- Socket：可以用于不同机器间进程的通信，也可以用于本地进程通信



### Linux下同步机制？

- POSIX信号量：可用于进程同步，也可用于线程同步
- POSIX互斥锁 + 条件变量：只能用于线程同步



### 死锁是什么？

死锁是两个或以上的线程都在等待对方释放资源的过程，死锁会导致程序卡死



### 死锁产生的条件是什么？

1. **互斥条件**：进程对所需求的资源具有排他性，若有其他进程请求该资源，请求进程只能等待。
2. **不剥夺条件**：进程在所获得的资源未释放前，不能被其他进程强行夺走，只能自己释放。
3. **请求和保持条件**：进程当前所拥有的资源在进程请求其他新资源时，由该进程继续占有。
4. **循环等待条件**：存在一种进程资源循环等待链，链中每个进程已获得的资源同时被链中下一个进程所请求。



### 死锁的处理方法？

- 鸵鸟策略：装作死锁没有发生，忽略问题
- 死锁检测和死锁恢复：不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复
  - 利用抢占恢复
  - 利用回滚恢复
  - 通过杀死进程恢复
- 死锁预防：在程序运行之前预防发生死锁，破坏上述四个条件
- 死锁避免：在程序运行时避免发生死锁，银行家算法



### 几种典型的锁？

- 互斥锁：一次只能一个线程拥有互斥锁，其他线程只有等待，会进入阻塞状态，等待内核唤醒
- 自旋锁：当线程无法获得锁的时候，不会放弃CPU，而是会一直等待
- 读写锁：分为读锁和写锁，当读取共享资源的时候使用读锁，写共享资源的时候使用写锁。多个读者可以同时读，但是只允许一个写者写

上面都属于悲观锁，就是在访问共享资源之前，默认会修改，先加锁

- 乐观锁：在访问共享资源之前不加锁，而是先访问，修改完之后，再判断这段时间有没有发生冲突，如果没有冲突，操作完成。如果发生冲突，则操作失败







## 中断和异常

### 外中断和异常有什么区别？

外中断：由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理完成。此外还有时钟中断，控制台中断等

异常：是由 CPU 执行指令的内部事件引起，例如非法操作码，地址越界，算术溢出等



### 软中断？

为了避免 CPU 由于中断处理程序时间过长，从而影响正常程序的调度，把中断处理程序分为上下两个部分，

- 上半部：对应硬中断，由硬件触发中断，用来快速处理中断
- 下半部：对应软中断，由内核触发中断，用来异步处理上半部未完成的工作





## 其他

### 终端退出，终端运行的进程会怎样

终端退出时，会发送 `SIGHUP` 信号给对应的 bash 进程，bash 进程收到信号后，把他发给 Session 下的进程，如果进程没有对 `SIGHUP` 信号作特殊处理，那么进程就会随之关闭



### 如何让进程后台运行

（1）命令后面加上&即可，实际上，这样是将命令放入到一个作业队列中了

（2）ctrl + z 挂起进程，使用jobs查看序号，在使用bg %序号后台运行进程

（3）nohup + &，将标准输出和标准错误缺省会被重定向到 nohup.out 文件中，忽略所有挂断（SIGHUP）信号

（4）运行指令前面 + setsid，使其父进程编程init进程，不受HUP信号的影响

（5）将 命令+ &放在()括号中，也可以是进程不受HUP信号的影响



### 守护进程、僵尸进程和孤儿进程？

**孤儿进程**： 父进程退出，子进程还在运行，这些子进程就是孤儿进程，会被 init 进程收养，由 init 进程对它们完成状态收集工作

**僵尸进程**： 子进程退出，而父进程并没有调用 wait() 或 waitpid()，那么子进程的进程描述符仍然保存在系统中，这种进程称之为僵尸进程。

**守护进程**： 在后台运行的，没有控制终端与之相连的进程。它独立于控制终端，周期性地执行某种任务。Linux的大多数服务器就是用守护进程的方式实现的，如web服务器进程http等

一个守护进程的父进程是init进程，因为它真正的父进程在fork出子进程后就先于子进程exit退出了，所以它是一个由init继承的孤儿进程

守护进程的名称通常以d结尾，比如sshd、xinetd、crond等



### 常见的几种磁盘调度算法

1. 先来先服务：按照磁盘请求的顺序进行调度
2. 最短寻道时间：优先调度与当前磁头所在磁道距离最近的磁道
3. 电梯扫描法：电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向



### 抖动（颠簸现象）是什么？

刚刚换出的页面马上又要换入内存，刚刚换入的页面马上又要换出外存，这种频繁的页面调度行为称为抖动

主要原因是进程频繁访问的页面数目高于可用的物理块数(分配给进程的物理块不够)



### 常见内存分配方式有哪些？

- 从静态存储区域分配。内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量，static变量
-  在栈上创建。在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限
- 从堆上分配，亦称动态内存分配。程序在运行的时候用malloc或new申请任意多少的内存，程序员自己负责在何时用free或delete释放内存



### 冯诺依曼结构有哪几个模块？分别对应现代计算机的哪几个部分？

- 存储器：内存
- 控制器：南桥北桥
- 运算器：CPU
- 输入设备：键盘
- 输出设备：显示器、网卡

















# 计算机网络

## 基础篇

### TCP/IP 网络模型有哪几层？

TCP/IP 网络通常是由上到下分成 4 层，分别是**应用层，传输层，网络层和网络接口层**

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230504192349.png)





### 为什么需要 TCP 协议？ TCP 工作在哪一层？

因为 IP 层是不可靠的，并不保证网络包的按序交付以及网络包中数据的完整性

因此，如果需要保证交付数据的可靠性，就需要上层的协议 TCP 协议来保证。

该协议位于传输层，可以保证接受网络包是无损坏以及按照顺序的



### 什么是 TCP ？

TCP 是面向连接的，可靠的，基于字节流的传输层通信协议



### RPC是什么？

纯 TCP 是可以收发数据的，但是是个无边界的数据流，并不知道数据的起始位置，因此需要上层定义消息格式和定义消息边界。于是就有了各种协议，HTTP 和 各类 RPC 协议就是定义在 TCP 之上的应用层协议

RPC 从本质上来说不算是协议，而是一种调用方式，目的是希望程序员能够像调用本地方法一样去调用远端的服务方法。并且 RPC 有多种实现方式，不一定基于 TCP 协议

从发展历史来说，**HTTP 主要用于 B/S 架构，而 RPC 更多用于 C/S 架构**，但现在都在慢慢融合



### 常见缩写

MTU：最大传输单元，链路层的帧中的数据部分的最大字节数，以太网中的一般为1500字节。

MSS：最大报文段大小，TCP的报文段中的数据部分的最大字节数，MTU减去IPv4的Header和TCP的Header。IPv4的Header和TCP的Header一般都是20字节，则MSS=1500-20-20 = 1460字节

MSL：报文最大生存时间，报文在网络上存在的最长时间，TCP连接必须经过时间2MSL后才真正释放掉。Windows默认MSL为2分钟。

RTT：往返时间。
TTL：表示IP数据报在网络中的寿命，其单位为秒。在目前的实际应用中，常以“跳”为单位。该字段指定IP包被路由器丢弃之前允许通过的最大网段数量。



## HTTP

### HTTP 是什么？

http 是超文本传输协议，在计算机领域的**两点之间传输**文字、图片、音频、视频等**超文本数据**的**约定和规范**



### HTTP常见的状态码？

- 1xx：属于提示信息，是协议处理的中间状态，实际用的较少
- 2xx：表示服务器**成功**处理了客户端的请求
- 3xx：重定向，资源的位置发生了变动，需要客户端重新发送请求
- 4xx：客户端错误，请求报文有误，服务器无法处理
- 5xx：服务器错误，服务器内部处理时发生了错误



### HTTP 常见字段有哪些？

请求头字段

- Host字段：指定服务器的域名
- *Content-Length 字段*： 表明本次回应的数据长度
- *Connection 字段*：客户端要求服务器使用「HTTP 长连接」机制
- *Content-Type 字段*：用于服务器回应时，告诉客户端，本次数据是什么格式
- Accept-Encoding：客户端在请求时，说明自己可以接受哪些压缩方法
- *Content-Encoding 字段*：表示服务器返回的数据使用了什么压缩格式



### GET 和 POST 

**GET 的语义是从服务器获取指定的资源**，**POST 的语义是根据请求体对指定的资源做出处理**，

参数位置：GET是在URL的query中，POST一般是在请求体中，也可以在query中

参数大小：GET受限于浏览器 URL 的大小，POST是 1G

服务器数据接收：GET是接收一次，POST根据数据的大小，可以分成多次接收

适用场景：GET是从服务端获取数据，不做增删改查，POST是向服务器提交数据

安全性：GET因为是在URL中，安全性低，POST相对于GET，安全性更高一点



### HTTP 缓存有哪些实现方式？

对于一些重复的 http 请求，可以把这对「请求-响应」的数据都**缓存在本地**，下次访问就可以直接从本地读取，而不用访问服务器了

- 强制缓存：只要浏览器判断缓存没有过期，直接使用浏览器的本地缓存。Cache-Control 是相对时间，Expires 是绝对时间
- 协商缓存：与服务器端协商之后，通过协商结果判断是否使用浏览器的本地缓存



### HTTP/1.1 的优缺点？

优点：简单、灵活、易于扩展、应用广泛和跨平台

缺点：明文传输，不验证通信方的身份不安全



### HTTP/1.1 的性能如何？

HTTP 协议基于 TCP/IP，并且使用了请求-应答 的方式

- 长连接： HTTP/1.1 在 1.0 的基础上提出了长连接的通信方式，减少了重复的 TCP 连接，减轻了服务器负载
- 管道网络传输：在一个 TCP 连接中，客户端可以发出多个请求，只要第一个请求发出去了，就可以发出第二个请求，服务端必须按照接受请求的顺序对这些管道化请求进行相应
- 队头阻塞：当第一个请求被阻塞时，后面所有的请求都会阻塞



### HTTP 与 HTTPS 有哪些区别？

- HTTPS 解决了 HTTP 不安全的问题，在 TCP 和 HTTP 中间加入了 SSL/TLS 安全协议，使报文能够加密传输
- HTTP 只需要三次握手即可，HTTPS 还需要 SSL/TLS 握手后，才可进行加密传输
- HTTP 默认端口号是 80，HTTPS 默认端口号是 443
- HTTPS 协议需要向 CA 申请数字证书，来保证服务器的身份是可信的

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230504201302.png)



### HTTPS 解决了 HTTP 的哪些问题？

- **信息加密**：通过 SSL/TLS 层，对报文进行加密传输，防止被窃听
- **校验机制**：防止通信内容被篡改
- **身份证书**： 通过数字证书验证服务器的身份，防止冒充

实现方法：

- **混合加密**：**对称加密**和**非对称加密**结合
  - **公钥加密，私钥解密**。这个目的是为了**保证内容传输的安全**，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容；
  - **私钥加密，公钥解密**。这个目的是为了**保证消息不会被冒充**，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的
  - 非对称加密的用途主要在于**通过「私钥加密，公钥解密」的方式，来确认消息的身份**，我们常说的**数字签名算法**，就是用的是这种方式，不过私钥加密内容不是内容本身，而是**对内容的哈希值加密**
- **摘要算法 + 数字签名**：数字签名就是用私钥对内容进行加密，通过公钥进行解密
- **数字证书**：
  - 因为服务端的公钥发送给客户端的时候，可能会被中间人伪造，因此客户端并不能确保自己拿到的公钥是服务端的
  - 所以需要有一个权威的机构，用自己的私钥加密服务端的公钥，然后把「服务端信息 + 公钥 + 数字签名」打包成一个**数字证书**
  - 服务端把数字证书发送给客户端，客户端会使用 CA 的公钥对对数字签名进行解密，判断数字证书的真实性
  - 如果是真实的，就获得了服务端的公钥，然后再通过公钥加密传输信息

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230504204729.png)



### 公钥加密和私钥加密

- **公钥加密**，私钥解密的作用是加密信息。因为只有拥有私钥的人才可以获取信息明文。
- **私钥加密**，公钥解密的作用是身份认证。因为只有拥有私钥的人才可以发送信息密文。



### HTTPS 是如何建立连接的？其间交互了什么？

SSL/TLS 协议基本流程：

- 客户端向服务器索要并验证服务器的公钥。
- 双方协商生产「会话秘钥」。
- 双方采用「会话秘钥」进行加密通信。

前两步也就是 SSL/TLS 的建立过程，也就是 TLS 握手阶段。TLS 的「握手阶段」涉及**四次**通信，使用不同的密钥交换算法，TLS 握手流程也会不一样的，现在常用的密钥交换算法有两种：RSA 算法 和 ECDHE 算法。

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230504210741.png)



### HTTPS 一定安全可靠吗？

客户端通过浏览器向服务端发起 HTTPS 请求时，被「假基站」转发到了一个「中间人服务器」，于是客户端是和「中间人服务器」完成了 TLS 握手，然后这个「中间人服务器」再与真正的服务端完成 TLS 握手。

其实**HTTPS 协议本身到目前为止还是没有任何漏洞的，即使你成功进行中间人攻击，本质上是利用了客户端的漏洞（用户点击继续访问或者被恶意导入伪造的根证书），并不是 HTTPS 不够安全**。



### HTTP/1.1 相比 HTTP/1.0 提高了什么性能？

HTTP/1.1 相比 HTTP/1.0 性能上的改进：

- 使用长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。
- 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

但 HTTP/1.1 还是有性能瓶颈：

- 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 `Body` 的部分；
- 发送冗长的首部。每次互相发送相同的首部造成的浪费较多；
- 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；
- 没有请求优先级控制；
- 请求只能从客户端开始，服务器只能被动响应。



### HTTP/2 做了什么优化？有什么缺陷？

HTTP/2 是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230516145209.png)



HTTP/2 相比 HTTP/1.1 性能上的改进：

- **头部压缩**：同时发出多个请求，具有相似的头部，那么协议就会消除重复的部分
- **二进制格式**：头信息和数据体全部采用二进制数据，提高传输效率
- **并发传输**：1 个 TCP 连接包含多个 Stream，Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成。Message 里包含一条或者多个 Frame，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内容（头部和包体）
- **服务器主动推送资源**：服务端不再是被动地响应，可以**主动**向客户端发送消息。



HTTP/2 还是存在“队头阻塞”的问题



### HTTP/3 做了哪些优化？

- HTTP/1.1 中的管道（ pipeline）虽然解决了请求的队头阻塞，但是**没有解决响应的队头阻塞**，因为服务端需要按顺序响应收到的请求，如果服务端处理某个请求消耗的时间比较长，那么只能等响应完这个请求后， 才能处理下一个请求，这属于 HTTP 层队头阻塞。
- HTTP/2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是**一旦发生丢包，就会阻塞住所有的 HTTP 请求**，这属于 TCP 层队头阻塞。

HTTP/2 队头阻塞的问题是因为 TCP，所以 **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！**

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230516151109.png)

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230516151803.png)

QUIC 有以下 3 个特点

- **无队头阻塞**：当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题
- **更快的连接建立**：HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，需要分别进行握手，但是 QUIC 内部包含了 TLS，握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的
- **连接迁移**：通过**连接 ID** 来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能



### HTTP/1.1 如何优化？

可以从下面这三种优化思路来优化 HTTP/1.1 协议：

- 尽量避免发送 HTTP 请求：使用缓存
- 在发送 HTTP 请求时，减少请求次数：减少重定向次数、合并请求、延迟发送请求
- 减少 HTTP 响应的数据：有损压缩和无损压缩



## TCP

### 什么是 TCP ？

- 面向连接的：一对一连接，不是 UDP 协议那种一个主机同时向多个主机发送消息
- 可靠的：无论网络链路中出现怎样的变化，TCP 都保证一个报文一定到达接收端
- 字节流：消息通过 TCP 传输的时候，可能会被分组成多个 TCP 报文，接收方不知道消息的边界，是无法读出有效的信息。同时 TCP 报文是有序的，当前一个报文没有接收到时，即使接受了后面的报文，也不会给到应用层去处理



### 如何理解是 TCP 面向字节流协议？

当用户消息通过 UDP 协议传输时，**操作系统不会对消息进行拆分**，在组装好 UDP 头部后就交给网络层来处理，所以发出去的 UDP 报文中的数据部分就是完整的用户消息，也就是**每个 UDP 报文就是一个用户消息的边界**，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息

当用户消息通过 TCP 协议传输时，操作系统可能会分成多个报文发送，这时，接收方应用程序如果不知道发送的消息长度，是没有办法读出一个有效的用户消息

**TCP 粘包问题**：当两个消息的某个部分被分到同一个 TCP 报文

![](https://raw.githubusercontent.com/vaesong/Images/master/20230523202914.png)



### 如何解决粘包？

粘包主要是因为不知道数据的边界，一般三种方式

- 固定长度的消息
- 特殊字符作为边界，例如 HTTP ，使用 \r\t
- 自定义消息结构



### 为什么是三次握手？不是两次、四次？

1. 避免历史连接：
   - 在网络拥堵的情况下，先发的 **旧 SYN 报文** 比后发的 **新 SYN 报文** 先到达，那么服务端就会返回一个 SYN+ACK 报文，不过此时的 ACK 是旧的。当客户端收到后，发现不是期望的 新 SYN 报文，就会发送 RST 报文，释放连接。
   - 后续新的 SYN 报文抵达服务端后，再重新建立连接
   - 如果是**两次**，服务端收到旧 SYN 报文就建立连接，进入 ESTABLISHED 状态，而客户端会发送 RST 报文来断开连接，这样会造成资源的浪费
2. 同步双方初始序列号：
   - TCP 通信的双方，都需要维护一个序列号，可以可靠的接收数据，可以去除重复数据，可以按照顺序接收。
   - 三次握手可以确保双方的初始序列号同步
3. 避免资源浪费：
   - 网络拥堵时，客户端重发自己的 SYN 报文，如果服务端接收到之后，就建立连接（两次握手），那么等拥堵的 SYN 到之后，再次建立连接，就会造成资源的浪费。（但是三次握手的话，服务端接收到重发的 SYN ，还会重新建立连接吗？？？）





### 为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？

为了防止历史报文被新的相同四元组的连接接收

考虑下面一种情况，假设每次建立连接，客户端和服务端的初始化序列号都是从 0 开始：

- 客户端第一次和服务端建立连接，然后发送的数据在网络中阻塞了，然后超时重传了这个数据
- 服务端重启，关闭了刚才的连接，于是发送 RST 报文终止和客户端的连接
- 客户端建立第二次连接，建立成功后，第一次连接的数据包到达，被第二次连接接收

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230517213031.png)



### [#](https://xiaolincoding.com/network/3_tcp/tcp_interview.html#既然-ip-层会分片-为什么-tcp-层还需要-mss-呢)既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230517213657.png)

- 首先，如果没有 MSS 的长度，那么在 IP 层发现 MTU 过大，就会进行分片传输，但是一个 IP 分片丢失的时候，整个 IP 报文的分片都要重传（因为 IP 没有超时重传机制，需要由 TCP 来负责，重发整个 TCP 报文（TCP 头 + 数据））
- 但是，如果定义了 MSS 的大小，就会在 TCP 传输数据的时候，超过 MSS 就会分片，从而形成的 IP 包的长度一定不大于 MTU ，而不用触发 IP 分片



### 第一次握手丢失了，会发生什么？

当客户端想和服务端建立连接的时候，发送 SYN 报文，进入 `SYN_SENT` 状态，如果迟迟接收不到服务端的 SYN+ACK 报文，就会重发 SYN 报文

内核会规定重传的次数。**每次超时的时间是上一次的 2 倍**



### 第二次握手丢失了，会发生什么？

当服务端收到客户端的第一次握手后，就会回 SYN-ACK 报文给客户端，这个就是第二次握手，此时服务端会进入 `SYN_RCVD` 状态

当第二次握手丢失了，客户端和服务端都会重传：

- 客户端会重传 SYN 报文，也就是第一次握手，最大重传次数由 `tcp_syn_retries`内核参数决定
- 服务端会重传 SYN-ACK 报文，也就是第二次握手，最大重传次数由 `tcp_synack_retries` 内核参数决定



### 第三次握手丢失了，会发生什么？

客户端收到 SYN+ACK 报文后，发送 ACK 报文，然后进入 `ESTABLISH` 状态，但是报文丢失，于是服务端迟迟接收不到 ACK 报文，就会重传 SYN+ACK 报文

- 如果客户端没发送数据包，一直处于 `ESTABLISHED` 状态，然后经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接，于是客户端连接就会断开连接。
- 如果客户端发送了数据包，一直没有收到服务端对该数据包的确认报文，则会一直重传该数据包，直到重传次数超过 `tcp_retries2` 值（默认值 15 次）后，客户端就会断开 TCP 连接。

**ACK 报文是不会重传的？？？**



### 什么是 SYN 攻击？如何避免 SYN 攻击？

假设攻击者短时间伪造不同 IP 地址的 `SYN` 报文，服务端每接收到一个 `SYN` 报文，就进入`SYN_RCVD` 状态，但服务端发送出去的 `ACK + SYN` 报文，无法得到未知 IP 主机的 `ACK` 应答，久而久之就会**占满服务端的半连接队列**，使得服务端不能为正常用户服务

在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：

- 半连接队列，也称 SYN 队列；
- 全连接队列，也称 accept 队列；



避免 SYN 攻击方式，可以有以下四种方法：

- 调大 netdev_max_backlog，当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包，要适当调大该参数的值
- 增大 TCP 半连接队列；
- 开启 tcp_syncookies，开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接，相当于绕过了 SYN 半连接来建立连接
- 减少 SYN+ACK 重传次数



### SYN 报文什么时候情况下会被丢弃？

- 开启 tcp_tw_recycle 参数，并且在 NAT 环境下，造成 SYN 报文被丢弃
- TCP 两个队列满了（半连接队列和全连接队列），造成 SYN 报文被丢弃



### 已建立连接的TCP，收到SYN会发生什么？

一个已经建立的 TCP 连接，客户端中途宕机了，而服务端此时也没有数据要发送，一直处于 Established 状态，客户端恢复后，向服务端建立连接，此时服务端会怎么处理？

两种情况，看端口：

- 第一种是客户端建立连接的四元组和之前的不同，那么就会被认为是新的TCP连接，完成三次握手

- 第二种客户端建立连接的四元组和之前相同

  - 收到了客户端的 SYN 报文（注意此时的 SYN 报文其实是乱序的，因为 SYN 报文的初始化序列号其实是一个随机数），会回复一个携带了正确序列号和确认号的 ACK 报文，这个 ACK 被称之为 Challenge ACK。

    接着，客户端收到这个 Challenge ACK，发现确认号（ack num）并不是自己期望收到的，于是就会回 RST 报文，服务端收到后，就会释放掉该连接





### TCP 和 UDP 可以使用同一个端口吗？

可以， TCP 和 UDP 可以**绑定**同一个端口

在数据链路层，通过 MAC 地址来寻找局域网内的主机。

在网络层，通过 IP 地址来寻找网络中互连的主机或路由器。

在传输层，通过 端口 来识别同时通信的不同应用程序

传输层有两个协议，一个是 TCP 一个是 UDP，在内核中是完全独立的软件模块。当主机收到数据包时，可以根据 IP 包头的协议号字段知道该数据包是 TCP/UDP，所以可以确定是那个模块处理，从而确定哪个应用程序



### 多个 TCP 服务进程可以绑定同一个端口吗？

如果两个 TCP 进程绑定的 IP 和端口都是一样的，那执行 bind() 的时候就会出现错误。（可以设置 socket 的 SO_REUSEPORT 属性，仅限于前一个进程处于 TIME_WAIT 状态）

两个 TCP 进程绑定的 IP 不同时，是可以的



### 客户端的端口可以重复使用吗？

**TCP 连接是由四元组（源IP地址，源端口，目的IP地址，目的端口）唯一确认的，那么只要四元组中其中一个元素发生了变化，那么就表示不同的 TCP 连接的**



### 客户端 TCP 连接 TIME_WAIT 状态过多，会导致端口资源耗尽而无法建立新的连接吗？

这个需要看连接的是不是同一个服务端（注意这里是服务端 IP 和 端口都一样），如果是同一个服务端，那么就会造成端口资源耗尽

如果不是同一个，就是不同的 TCP 连接，就可以重复使用端口



解决办法：

打开 `net.ipv4.tcp_tw_reuse` 这个内核参数。

因为开启了这个内核参数后，客户端调用 connect 函数时，如果选择到的端口，已经被相同四元组的连接占用的时候，就会判断该连接是否处于 TIME_WAIT 状态，如果该连接处于 TIME_WAIT 状态并且 TIME_WAIT 状态持续的时间超过了 1 秒，那么就会重用这个连接，然后就可以正常使用该端口了。





### TCP 四次挥手过程是怎样的？

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230518113009.png)

**主动关闭连接的，才有 TIME_WAIT 状态**



###  为什么挥手需要四次？

- 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务端收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接



### 优雅关闭 TCP 连接

- close 函数，同时 socket 关闭发送方向和读取方向，socket 不再有发送和接收数据的能力
- shutdown 函数，可以指定 socket 只关闭发送方向而不关闭读取方向， socket 不再有发送数据的能力，但是还是具有接收数据的能力



### 什么情况会出现三次挥手？

当被动关闭方（上图的服务端）在 TCP 挥手过程中，「**没有数据要发送」并且「开启了 TCP 延迟确认机制」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手**



### 什么是 TCP 延迟确认机制？

如果只发送 ACK 而不携带数据的话，效率很低，于是采用了延迟确认机制

- 如果有数据发送，则 ACK 和数据一起发送
- 如果暂时没有数据发送，就等待一段时间，看是否有数据
- 在等待的时候对方的数据到达了，就不等了，直接发送 ACK



### 第一次挥手丢失了，会发生什么？

客户端重传 FIN 报文，重传次数的规定好的，每次重传的等待时间翻倍



### 第二次挥手丢失了，会发生什么？

ACK 报文不会重传，于是客户端的 FIN 重传



### 第三次挥手丢失了，会发生什么？

当服务端收到客户端的 FIN 报文的时候，会发送 ACK 确认报文，然后进入 CLOSE_WAIT 状态，等待应用程序主动调用 close 函数关闭连接（内核是没有权利关闭连接的）

当调用 close 函数关闭连接，发送 FIN 报文丢失后，会超时重传

客户端处于 FIN_WAIT_2 状态的时长是有限的，如果规定时间内没收到 FIN 报文，就会直接断开连接



### 第四次挥手丢失了，会发生什么？

当客户端收到服务端的第三次挥手的 FIN 报文后，就会回 ACK 报文，也就是第四次挥手，此时客户端连接进入 `TIME_WAIT` 状态

服务端（被动关闭方）没有收到 ACK 报文前，还是处于 LAST_ACK 状态

如果第四次挥手的 ACK 报文没有到达服务端，服务端就会重发 FIN 报文，重发次数仍然由 `tcp_orphan_retries` 参数控制



### 四次挥手中收到乱序的 FIN 包会如何处理？

如果 FIN 报文比数据包先抵达客户端，此时 FIN 报文其实是一个乱序的报文，此时客户端的 TCP 连接并不会从 FIN_WAIT_2 状态转换到 TIME_WAIT 状态

![](https://raw.githubusercontent.com/vaesong/Images/master/20230523204659.png)

在 FIN_WAIT_2 状态时，如果收到乱序的 FIN 报文，那么就被会加入到「乱序队列」，并不会进入到 TIME_WAIT 状态

等再次收到前面被网络延迟的数据包时，会判断乱序队列有没有数据，然后会检测乱序队列中是否有可用的数据，如果能在乱序队列中找到与当前报文的序列号保持的顺序的报文，就会看该报文是否有 FIN 标志，如果发现有 FIN 标志，这时才会进入 TIME_WAIT 状态



### 在 TIME_WAIT 状态的 TCP 连接，收到 SYN 后会发生什么？

关键是要看 SYN 的「序列号和时间戳」是否合法：

- **合法 SYN**：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要**大**，**并且** SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要**大**。
- **非法 SYN**：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要**小**，**或者** SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要**小**。

收到「合法的 SYN 」后，就会**重用此四元组连接，跳过 2MSL 而转变为 SYN_RECV 状态，接着就能进行建立连接过程**

![](https://raw.githubusercontent.com/vaesong/Images/master/20230523210232.png)



收到「非法的 SYN 」后，就会**再回复一个第四次挥手的 ACK 报文，客户端收到后，发现并不是自己期望收到确认号（ack num），就回 RST 报文给服务端**

![](https://raw.githubusercontent.com/vaesong/Images/master/20230523210303.png)





### 为什么 TIME_WAIT 等待的时间是 2MSL？

`MSL` 是 Maximum Segment Lifetime，**报文最大生存时间**，超过这个时间报文将被丢弃

如果被动关闭方（服务端）没有收到断开连接的最后的 ACK 报文，就会触发超时重发 `FIN` 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方， 一来一去正好 2 个 MSL



### 为什么需要 TIME_WAIT 状态？

- **保证连接能够正确的关闭**，例如客户端最后发送的 ACK 在网络中丢失，然后服务端会超时重传，因此在 TIME_WAIT 状态可以接收到 FIN 报文，从而再次发送 ACK 报文
- **防止历史连接的数据，被新的相同四元组连接错误的接收**，如果之前连接发送的数据包在网络中因阻塞而延迟到达，这时候该 TCP 连接完成了四次挥手，并且通过三次握手重新建立了一个新的相同四元组连接，然后，延迟的数据到达，但是是上个连接的数据，被错误的接收了



### TIME_WAIT 过多有什么危害？

- 第一是占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等；
- 第二是占用端口资源，端口资源也是有限的，一般可以开启的端口为 `32768～61000`，也可以通过 `net.ipv4.ip_local_port_range`参数指定范围



### 如何优化 TIME_WAIT？

这里给出优化 TIME-WAIT 的几个方式，都是有利有弊：

- 打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项
- net.ipv4.tcp_max_tw_buckets
- 程序中使用 SO_LINGER ，应用强制使用 RST 关闭



### 服务器出现大量 TIME_WAIT 状态的原因有哪些？

 TIME_WAIT 状态是主动关闭连接方才会出现的状态，所以如果服务器出现大量的 TIME_WAIT 状态的 TCP 连接，就是说明服务器主动断开了很多 TCP 连接

问题来了，**什么场景下服务端会主动断开连接呢？**

- 第一个场景：HTTP 没有使用长连接，在完成一次 HTTP 请求/处理后，就会关闭连接，默认由服务端主动关闭连接
- 第二个场景：HTTP 长连接超时，如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，定时器的时间一到，nginx 就会触发回调函数来关闭该连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接
- 第三个场景：HTTP 长连接的请求数量达到上限，当超过最大限制时，服务端就会主动关闭连接



### 服务器出现大量 CLOSE_WAIT 状态的原因有哪些？

当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序没有调用 close 函数关闭连接

一个普通的 TCP 服务端的流程：

1. 创建服务端 socket，bind 绑定端口、listen 监听端口
2. 将服务端 socket 注册到 epoll
3. epoll_wait 等待连接到来，连接到来时，调用 accpet 获取已连接的 socket
4. 将已连接的 socket 注册到 epoll
5. epoll_wait 等待事件发生
6. 对方连接关闭时，我方调用 close

**第一个原因**：第 2 步没有做，没有将服务端 socket 注册到 epoll，这样有新连接到来时，服务端没办法感知这个事件，也就无法获取到已连接的 socket，那服务端自然就没机会对 socket 调用 close 函数了。

不过这种原因发生的概率比较小，这种属于明显的代码逻辑 bug，在前期 read view 阶段就能发现的了。

**第二个原因**： 第 3 步没有做，有新连接到来时没有调用 accpet 获取该连接的 socket，导致当有大量的客户端主动断开了连接，而服务端没机会对这些 socket 调用 close 函数，从而导致服务端出现大量 CLOSE_WAIT 状态的连接。

发生这种情况可能是因为服务端在执行 accpet 函数之前，代码卡在某一个逻辑或者提前抛出了异常。

**第三个原因**：第 4 步没有做，通过 accpet 获取已连接的 socket 后，没有将其注册到 epoll，导致后续收到 FIN 报文的时候，服务端没办法感知这个事件，那服务端就没机会调用 close 函数了。

发生这种情况可能是因为服务端在将已连接的 socket 注册到 epoll 之前，代码卡在某一个逻辑或者提前抛出了异常。之前看到过别人解决 close_wait 问题的实践文章，感兴趣的可以看看：[一次 Netty 代码不健壮导致的大量 CLOSE_WAIT 连接原因分析(opens new window)](https://mp.weixin.qq.com/s?__biz=MzU3Njk0MTc3Ng==&mid=2247486020&idx=1&sn=f7cf41aec28e2e10a46228a64b1c0a5c&scene=21#wechat_redirect)

**第四个原因**：第 6 步没有做，当发现客户端关闭连接后，服务端没有执行 close 函数，可能是因为代码漏处理，或者是在执行 close 函数之前，代码卡在某一个逻辑，比如发生死锁等等。

出现 CLOSE_WAIT 状态是在四次挥手的过程中，说明已经建立了 TCP 连接，并且已经接收到了客户端的 FIN 报文，感觉只有第 6 步出现问题





### 如果已经建立了连接，但是客户端突然出现故障了怎么办？

客户端的主机发生了宕机，或者断电，如果服务端一直不会发送数据给客户端，那么服务端是永远无法感知到客户端宕机这个事件

为了避免这种情况，TCP 搞了个**保活机制**（TCP keepalive）

定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序



### 如果已经建立了连接，但是服务端的进程崩溃会发生什么？

TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 FIN 报文，后续的挥手过程也都是在内核完成，并不需要进程的参与，所以即使服务端的进程退出了，还是能与客户端完成 TCP 四次挥手的过程



### TCP 连接，一端断电和进程崩溃有什么区别？

在没有使用 TCP 保活机制且双方不传输数据的情况下，一方的 TCP 连接处在 ESTABLISHED 状态，并不代表另一方的连接还一定正常

**主机崩溃**：由于没有开启 TCP 的保活机制，那么服务端就不会给客户端发送探测报文，于是感知不到客户端断连，**将会一直处于 ESTABLISHED 连接状态**，直到服务端重启进程

**进程崩溃**：由内核会回收该进程的所有 TCP 连接资源，于是内核会发送第一次 FIN 报文，完成四次挥手过程



### 客户端主机宕机，又迅速重启

在客户端主机宕机后，服务端向客户端发送的报文会得不到任何的响应，在一定时长后，服务端就会触发**超时重传**机制，重传未得到响应的报文

服务端重传报文的过程中，客户端主机重启完成后，客户端的内核就会接收重传的报文，然后根据报文的信息传递给对应的进程

- 如果客户端主机上**没有**进程绑定该 TCP 报文的目标端口号，那么客户端内核就会**回复 RST 报文，重置该 TCP 连接**
- 如果客户端主机上**有**进程绑定该 TCP 报文的目标端口号，由于客户端主机重启后，之前的 TCP 连接的数据结构已经丢失了，客户端内核里协议栈会发现找不到该 TCP 连接的 socket 结构体，于是就会**回复 RST 报文，重置该 TCP 连接**

**只要有一方重启完成后，收到之前 TCP 连接的报文，都会回复 RST 报文，以断开连接**



### 客户端主机宕机，一直没有重启

这种情况，服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，于是服务端的 TCP 连接就会断开



### 拔掉网线后， 原本的 TCP 连接还存在吗？

实际上，TCP 连接在 Linux 内核中是一个名为 `struct socket` 的结构体，该结构体的内容包含 TCP 连接的状态等信息。当拔掉网线的时候，操作系统并不会变更该结构体的任何内容，所以 TCP 连接的状态也不会发生改变

拔掉网线这个动作并不会影响 TCP 连接的状态，另外还要看是否有数据传输

有数据传输的情况：

- 客户端拔掉网线后，服务端会超时重发数据报文，在还没达到最大重发次数之前，客户端插上网线，就可以正常通信
- 客户端没有在最大重发次数之前插上网线，服务端会断开连接。等到客户端插回网线后，向服务端发送数据，因为服务端已经断开了与客户端相同四元组的 TCP 连接，所以就会回 RST 报文，客户端收到后就会断开 TCP 连接

没有数据传输的情况下：

- 如果双方都没有开启 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，那么客户端和服务端的 TCP 连接状态将会一直保持存在。
- 如果双方都开启了 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，TCP keepalive 机制会探测到对方的 TCP 连接没有存活，于是就会断开 TCP 连接。而如果在 TCP 探测期间，客户端插回了网线，那么双方原本的 TCP 连接还是能正常存在。



### 服务端没有 listen，客户端发起连接建立，会发生什么？

服务端如果只 bind 了 IP 地址和端口，而没有调用 listen 的话，然后客户端对服务端发起了连接建立，服务端会回 RST 报文。



### 不使用 listen ，可以建立 TCP 连接吗？

是可以的，客户端是可以自己连自己的形成连接（TCP自连接），也可以两个客户端同时向对方发出请求建立连接（TCP同时打开），这两个情况都有个共同点，就是没有服务端参与，也就是没有listen，就能建立连接

执行 listen 方法时，会创建半连接队列和全连接队列，因为客户端没有执行listen，但内核还有个全局 hash 表，可以用于存放 sock 连接的信息

在 TCP 自连接的情况中，客户端在 connect 方法时，最后会将自己的连接信息放入到这个全局 hash 表中，然后将信息发出，消息在经过回环地址重新回到 TCP 传输层的时候，就会根据 IP + 端口信息，再一次从这个全局 hash 中取出信息。于是握手包一来一回，最后成功建立连接



### accept 发生在三次握手的哪一步？

客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后



### 没有 accept，能建立 TCP 连接吗？

accpet 系统调用并不参与 TCP 三次握手过程，它只是负责从 TCP 全连接队列取出一个已经建立连接的 socket，用户层通过 accpet 系统调用拿到了已经建立连接的 socket，就可以对该 socket 进行读写操作了。

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230518143656.png)

- **每一个**`socket`执行`listen`时，内核都会自动创建一个半连接队列和全连接队列。
- 第三次握手前，TCP连接会放在半连接队列中，直到第三次握手到来，才会被放到全连接队列中。
- `accept方法`只是为了从全连接队列中拿出一条连接，本身跟三次握手几乎**毫无关系**。
- 出于效率考虑，虽然都叫队列，但半连接队列其实被设计成了**哈希表**，而全连接队列本质是链表。
- 全连接队列满了，再来第三次握手也会丢弃，此时如果`tcp_abort_on_overflow=1`，还会直接发`RST`给客户端。
- 半连接队列满了，可能是因为受到了`SYN Flood`攻击，可以设置`tcp_syncookies`，绕开半连接队列。
- 客户端没有半连接队列和全连接队列，但有一个**全局hash**，可以通过它实现自连接或TCP同时打开。



## TCP 重传、滑动窗口、流量控制、拥塞控制

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230518144631.png)



### 超时重传

TCP 针对数据包丢失的情况，会用**重传机制**解决。

- 超时重传：发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据
- 快速重传：快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。面临着另外一个问题。就是**重传的时候，是重传一个，还是重传所有的问题**
- SACK 方法（选择性确认）：TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将已收到的数据的信息发送给「发送方」**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**
- Duplicate SACK：主要**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了**





### 引入窗口概念的原因

TCP 是每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了， 再发送下一个。但这种方式的缺点是效率比较低的。

TCP 引入了**窗口**这个概念，窗口大小就是指**无需等待确认应答，而可以继续发送数据的最大值**

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230522194520.png)

ACK 600 确认应答报文丢失，也没关系，因为可以通过下一个确认应答进行确认，只要发送方收到了 ACK 700 确认应答，就意味着 700 之前的所有数据「接收方」都收到了。这个模式就叫**累计确认**或者**累计应答**



### 窗口大小由哪一方决定？

TCP 头里有一个字段叫 `Window`，也就是窗口大小。

**这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。**

所以，通常窗口的大小是由接收方的窗口大小来决定的。



### 发送窗口和接收窗口

TCP 滑动窗口方案使用三个指针来跟踪在四个传输类别中的每一个类别中的字节。其中两个指针是绝对指针（指特定的序列号），一个是相对指针（需要做偏移）

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230522194912.png)

- `SND.WND`：表示发送窗口的大小（大小是由接收方指定的）；
- `SND.UNA`（*Send Unacknoleged*）：是一个绝对指针，它指向的是已发送但未收到确认的第一个字节的序列号，也就是 #2 的第一个字节。
- `SND.NXT`：也是一个绝对指针，它指向未发送但可发送范围的第一个字节的序列号，也就是 #3 的第一个字节。



### 接收窗口和发送窗口的大小是相等的吗？

并不是完全相等，接收窗口的大小是**约等于**发送窗口的大小的。

因为滑动窗口并不是一成不变的



### 流量控制

**TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制**

为了简单起见，假设以下场景：

- 客户端是接收方，服务端是发送方
- 假设接收窗口和发送窗口相同，都为 `200`
- 假设两个设备在整个传输过程中都保持相同的窗口大小，不受外界影响

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230522200158.png)



### 操作系统的缓冲区，是如何影响发送窗口和接收窗口的呢？

当应用程序没有及时读取缓存时，发送窗口和接收窗口的变化。

考虑以下场景：

- 客户端作为发送方，服务端作为接收方，发送窗口和接收窗口初始大小为 `360`；
- 服务端非常的繁忙，当收到客户端的数据时，应用层不能及时读取数据。

![](https://raw.githubusercontent.com/vaesong/Images/master/20230522200908.png)



当服务端系统资源非常紧张的时候，操作系统可能会直接减少了接收缓冲区大小，这时应用程序又无法及时读取缓存数据，那么这时候就有严重的事情发生了，会出现数据包丢失的现象

**为了防止这种情况发生，TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，这样就可以避免了丢包情况**

![](https://raw.githubusercontent.com/vaesong/Images/master/20230522201008.png)



### 窗口关闭

**如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭**

当发生窗口关闭时，接收方处理完数据后，会向发送方通告一个窗口非 0 的 ACK 报文，

当后续有窗口可以使用的时候，发出新的通告，如果这个通告窗口的 ACK 报文在网络中丢失了。这会导致发送方一直等待接收方的非 0 窗口通知，接收方也一直等待发送方的数据，如不采取措施，这种相互等待的过程，会造成了死锁的现象

![](https://raw.githubusercontent.com/vaesong/Images/master/20230522201327.png)



为了解决这个问题，TCP 为每个连接设有一个持续定时器，**只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。**

如果持续计时器超时，就会发送**窗口探测 ( Window probe ) 报文**，而对方在确认这个探测报文时，给出自己现在的接收窗口大小

- 如果接收窗口仍然为 0，那么收到这个报文的一方就会重新启动持续计时器
- 如果接收窗口不是 0，那么死锁的局面就可以被打破了



### 糊涂窗口综合症

如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小。

到最后，**如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症**

![](https://raw.githubusercontent.com/vaesong/Images/master/20230522201948.png)

于是，要解决糊涂窗口综合症，就要同时解决上面两个问题就可以了：

- 让接收方不通告小窗口给发送方
- 让发送方避免发送小数据



怎么让接收方不通告小窗口呢？

- 当接收窗口比较小的时候，直接通告窗口为 0

怎么让发送方避免发送小数据呢？

- 使用 Nagle 算法：下面两个条件都不满足，发送方一直在囤积数据，直到满足发送条件
  - 条件一：要等到窗口大小 >= `MSS` 并且 数据大小 >= `MSS`；
  - 条件二：收到之前发送数据的 `ack` 回包；



### 拥塞控制

在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大....

**拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**。

我们在前面提到过发送窗口 `swnd` 和接收窗口 `rwnd` 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。

拥塞窗口 `cwnd` 变化的规则：

- 只要网络中没有出现拥塞，`cwnd` 就会增大；
- 但网络中出现了拥塞，`cwnd` 就减少；



拥塞控制主要是四个算法：

- 慢启动
- 拥塞避免
- 拥塞发生
- 快速恢复



### 慢启动算法

**当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1**

慢启动算法，发包的个数是**指数性的增长**

![](https://raw.githubusercontent.com/vaesong/Images/master/20230522203313.png)

有一个叫慢启动门限 `ssthresh` （slow start threshold）状态变量。

- 当 `cwnd` < `ssthresh` 时，使用慢启动算法。
- 当 `cwnd` >= `ssthresh` 时，就会使用「拥塞避免算法」。



### 拥塞避免算法

当拥塞窗口 `cwnd` 「超过」慢启动门限 `ssthresh` 就会进入拥塞避免算法。

进入拥塞避免算法后，它的规则是：**每当收到一个 ACK 时，cwnd 增加 1/cwnd**

拥塞避免算法就是将原本慢启动算法的指数增长变成了**线性增长**，还是增长阶段，但是增长速度缓慢了一些

![](https://raw.githubusercontent.com/vaesong/Images/master/20230522203524.png)



### 拥塞发生

当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：

- 超时重传
- 快速重传



当发生了「超时重传」，则就会使用拥塞发生算法。

这个时候，ssthresh 和 cwnd 的值会发生变化：

- `ssthresh` 设为 `cwnd/2`，
- `cwnd` 重置为 `1` （是恢复为 cwnd 初始化值，我这里假定 cwnd 初始化值 1）

![](https://raw.githubusercontent.com/vaesong/Images/master/20230522204207.png)



还有更好的方式，前面我们讲过「快速重传算法」。当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。

TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 `ssthresh` 和 `cwnd` 变化如下：

- `cwnd = cwnd/2` ，也就是设置为原来的一半;
- `ssthresh = cwnd`;
- 进入快速恢复算法



### 快速恢复

进入快速恢复算法如下：

- 拥塞窗口 `cwnd = ssthresh + 3` （ 3 的意思是确认有 3 个数据包被收到了）；
- 重传丢失的数据包；
- 如果再收到重复的 ACK，那么 cwnd 增加 1；
- 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；

![](https://raw.githubusercontent.com/vaesong/Images/master/20230522204804.png)



> 快速恢复算法过程中，为什么收到新的数据后，cwnd 设置回了 ssthresh ？
>
> 我的理解是：
>
> 1. 在快速恢复的过程中，首先 ssthresh = cwnd/2，然后 cwnd = ssthresh + 3，表示网络可能出现了阻塞，所以需要减小 cwnd 以避免，加 3 代表快速重传时已经确认接收到了 3 个重复的数据包；
> 2. 随后继续重传丢失的数据包，如果再收到重复的 ACK，那么 cwnd 增加 1。加 1 代表每个收到的重复的 ACK 包，都已经离开了网络。这个过程的目的是尽快将丢失的数据包发给目标。
> 3. 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，恢复过程结束。
>
> **首先，快速恢复是拥塞发生后慢启动的优化，其首要目的仍然是降低 cwnd 来减缓拥塞，所以必然会出现 cwnd 从大到小的改变。**
>
> **其次，过程2（cwnd逐渐加1）的存在是为了尽快将丢失的数据包发给目标，从而解决拥塞的根本问题（三次相同的 ACK 导致的快速重传），所以这一过程中 cwnd 反而是逐渐增大的。**













# 数据库

## MYSQL

### MySQL 执行流程是怎样的？

![](https://raw.githubusercontent.com/vaesong/Images/master/20230524224423.png)

MySQL 的架构共分为两层：**Server 层和存储引擎层**

- **Server 层负责建立连接、分析和执行 SQL**：MySQL 大多数的核心功能模块都在这实现，主要包括连接器，查询缓存、解析器、预处理器、优化器、执行器等。另外，所有的内置函数（如日期、时间、数学和加密函数等）和所有跨存储引擎的功能（如存储过程、触发器、视图等。）都在 Server 层实现
- **存储引擎层负责数据的存储和提取**：支持 InnoDB、MyISAM、Memory 等多个存储引擎，不同的存储引擎共用一个 Server 层



连接器：建立连接，管理连接、校验用户身份；

查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执行。MySQL 8.0 已删除该模块；

解析 SQL，通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型；

执行 SQL：执行 SQL 共有三个阶段：

- 预处理阶段：检查表或字段是否存在；将 `select *` 中的 `*` 符号扩展为表上的所有列。
- 优化阶段：基于查询成本的考虑， 选择查询成本最小的执行计划；
- 执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端；



### MySQL 的连接数有限制吗？

MySQL 服务支持的最大连接数由 max_connections 参数控制

MySQL 的连接也跟 HTTP 一样，有短连接和长连接的概念

短连接执行一次 SQL 语句就会断开连接，长连接可以执行多条 SQL 语句



### 怎么解决长连接占用内存的问题？

第一种，**定期断开长连接**。既然断开连接后就会释放连接占用的内存资源，那么我们可以定期断开长连接

第二种，**客户端主动重置连接**。MySQL 5.7 版本实现了 `mysql_reset_connection()` 函数的接口



### 连接器的工作

- 与客户端进行 TCP 三次握手建立连接
- 校验客户端的用户名和密码，如果不对，就会报错
- 如果都对了，会判断该用户的权限，然后后面的逻辑权限都会基于此时读到的权限



# Webserver

### 为什么要做这个项目？

当刚学完C++语法的时候，看完 C++ primer 与 TCP/IP 网络编程 以及 游双的 Linux 高性能网络编程，想要通过项目来提升编程能力，其中 webserver 就是 C++ 中很经典的项目

该项目使用了网络编程技术，用到了很多比较经典的技术方法，可以快速的帮助我实践网络编程，搭建自己的服务器



### 介绍下你的项目？

该项目使用了线程池技术高并发的快速处理请求

使用 非阻塞 socket 和 epoll 技术实现对连接客户端的请求监听（连接，EPOLLIN，EPOLLOUT等），触发方式 ET 和 LT 都实现了

事件处理模式使用了Reactor 和 模拟 Proactor 模式都实现

在解析请求方面，使用了状态机解析HTTP报文请求，支持解析 GET 和简单的 POST 请求

实现了 web 端的用户注册，登录，可以请求服务器的图片和视频

使用的是同步日志记录服务器的运行状态

经过 Webbench 可以实现上万并发请求



### 线程池的成员变量有哪些？手写一下？

线程池的数量 m_thread_num, 线程池队列 m_threads, 请求的最大数量 m_max_requests, 请求队列 m_workqueue, 互斥锁 m_mutex, 信号量 m_sem



### 线程的同步机制有哪些？

有**4种**，临界区，互斥锁，信号量，条件变量

首先是临界区，通过多线程的互串行访问公共资源或一段代码，速度快，适合控制数据访问。

然后是互斥锁，当向线程池中的请求队列中加入请求或者拿出请求的时候，需要对其进行上锁，这样防止两个线程同时操作请求队列造成错误

然后是信号量，当有请求到来时，信号量加一，表示目前可以获得的请求多了一个，然后也会有线程请求信号量，拿到请求后，会把信号量减一

最后是条件变量，提供了线程间的一种通知机制，当某个共享数据达到某个值的时候，会以广播的方式唤醒等待的线程



### 线程池中的工作线程是一直等待吗？

线程池中的工作线程是处于一直阻塞等待的模式下的。

如果请求队列中目前没有请求，那么线程会 sem.wait() 等待新的请求进入到请求队列



### 你的线程池工作线程处理完一个任务后的状态是什么？

分**两种**情况考虑

（1） 当处理完任务后如果请求队列为空时，则这个线程重新回到阻塞等待的状态

（2） 当处理完任务后如果请求队列不为空时，那么这个线程将处于与其他线程竞争资源的状态，谁获得锁谁就获得了处理事件的资格。



### 如果同时1000个客户端进行访问请求，线程数不多，怎么能及时响应处理每一个呢？

本项目中是通过对子线程循环调用来解决高并发的问题的

在创建线程的时候，使用 `pthread_detach` 把线程分离，这样就不需要手动进行回收了。但是当子线程任务完成之后，它的资源会自动被系统回收。

这样的话，线程池就只能处理例如 8，10 个请求，这是不合理的。

于是，我们让线程进行 while 循环，即使它执行完了自己的任务，也不会被回收资源，而是一直循环等待的请求队列的请求，有的话，就获得请求，继续执行新的请求，没有的话，就阻塞等待。直到最后线程池被销毁



### 如果一个客户请求需要占用线程很久的时间，会不会影响接下来的客户请求呢，有什么好的策略呢?

会影响，因为线程池中的线程数量是有限的，如果用户长时间占用线程，会影响处理请求的效率。

可以为线程处理请求设置超时时间，超过设置的时间，就会通知线程，如果这个请求还在占用线程，就断开连接



### 简单说一下服务器使用的并发模型？

利用IO复用技术Epoll与线程池实现多线程的Reactor 和 模拟 Proactor 高并发模型

总的来说，使用主线程来监听事件，线程池中的多线程来处理请求

当使用 Reactor 处理模式的时候，主线程监只负责监听，当有客户端的请求，会把请求封装放进线程池中的请求队列，等待工作线程读取数据并且处理请求，最后处理完成之后， 触发 EPOLLOUT 事件，主线程检测到事件后，调用工作线程去进行写操作

当使用模拟 Proactor 处理模式的时候，主线程不仅负责监听事件，还同时读取数据和写数据。当有客户端请求的时候，会读出请求，之后再插入到线程池的请求队列。当工作线程处理完之后，会注册 EPOLLOUT 事件，由主线程负责写数据。



### 为什么 ET 要设置非阻塞 I/O？

当触发可读事件时，调用 read() 函数等，如果没有数据的话。阻塞 I/O 会等待直到有数据，非阻塞 I/O 会直接返回，通过 errno 判断

- 当是 LT 模式的时候，此时触发读事件，调用 read() 函数，此时有数据的话，拷贝到缓冲区。注意此时，如果一次读不完的话，因为没有 while 循环，所以会直接返回，但是，因为数据还没读完，所以会继续触发事件，继续调用 read () 函数。当数据全部读完了，那么也就不会触发读事件了。
- ok，如果设置为 阻塞 I/O ，当最后一次读完的时候，就不会触发读事件了，因此不会调用 read() ，不会阻塞
- 当是 ET 模式的时候，触发读事件，调用 read() 函数，因为需要一次读完，所以使用 while 循环。当读最后一次读完了所有的数据的时候，因为有 while 循环，仍然会调用 read() 函数，那么此时没有数据需要读。
- 如果设置的是 阻塞 I/O ，因为没有数据，会一直阻塞在 read() 那里，一直到有数据才可以继续进行，没办法出 while 循环。设置为非阻塞 I/O 的话，当没有数据的时候，会立即返回，可以根据 errno 判断是不是出错还是正常退出。

> 还有一种情况，就是当设置了 ET 模式下，如果读缓冲区太小，来不及读取数据的时候（**似乎不会出现这种情况**），同样会触发 errno 为 EAGAIN， EWOULDBLOCK，那么此时 break 之后，需要再次注册该 读事件，因为本次并没有读取完， ET 模式下并不会再次触发读事件，所以需要手动触发读事件 modfd 修改 EPOLLIN





### http连接请求处理

首先当浏览器发送HTTP请求过来的时候，主线程读取完成之后会把数据读取到 用户数组的 HTTP 对象的缓冲区中，然后把该对象插入到线程池中的任务队列，由线程池中的工作线程执行报文的解析，当解析完成之后，会触发 EPOLLOUT 事件，然后由主线程调用 HTTP 对象的写函数把数据从对象缓冲区写入到 Socket 的缓冲区中，发送给浏览器



### http报文解析处理流程

主要由两个函数，process_read() 和 process_write() ，一个用来解析 HTTP 报文，一个根据解析的结果生成相应报文

使用了主从状态机的转换来完成 HTTP 报文的解析，

首先，**主状态机**分为三个状态，分别代表当前在解析报文的哪个部分，包括解析请求行、请求头、请求体。**从状态机**是对一行读取的几种状态，包括，读取的行是完整的（LINE_OK）、读取的行是不完整的（LINE_OPEN）、读取的行是错误的（LINE_BAD）。从状态机读取一行，主状态机对一行进行解析，主状态机调用从状态机，从状态机驱动主状态机

从状态机从读缓冲区中进行读取，遇到 \r\n 就把它置为 \0 \0, 并且更新 m_checked_idx, 表示目前已经检查到的位置。主状态机初始状态是 CHECK_STATE_REQUESTLINE 表示正在解析请求行， 主状态机拿出已经处理过的一行数据，根据自己的状态，决定调用相应的函数对该行进行解析，如果解析成功就继续读取下一行，推动从状态机读取。最后，当读完请求之后，调用 do_request 对请求的内容进行判断，是否合法。最后，根据报文解析返回的状态码，调用 process_write() 函数生成响应报文。



### **http响应报文处理流程**

当报文解析完成之后，调用 process_write() 函数，首先根据返回的 HTTP 状态码判断，如果不是正常请求或者请求的文件没全新啊等，都是构建响应行，响应头以及空行和响应体

最后注册 EPOLLOUT 事件



### 用了状态机啊，为什么要用状态机？

传统的应用程序的执行流程基本是按照顺序执行的，遵循事先设定的逻辑，从头到尾执行。如果想在不同的状态下实现代码跳转，就需要破坏一些代码，这样就会造成代码逻辑混乱。所以必须采取不同的技术来处理这些情况。

**能够处理任何顺序的事件，并能提供有意义的响应--即使这些事件发生的顺序和预计的不同。**

有限状态机就是为了满足这一方面的要求而设计的，每个状态都有一系列的转移，每个转移和另外一个状态有关，当输入进来，如果和当前状态的某个转移匹配，机器转换为所指的状态，然后执行相应的代码。



### 状态机的转移图画一下？

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230317202552.png)



### https协议为什么安全？

https = http + TLS/SSL

TLS/SSL 协议位于应用层和 TCP 层之间，构建在 TCP 之上，由 TCP 协议保证数据传输的可靠性，任何数据到达 TCP 之前，都会经过 TLS/SSL 协议处理

之前的 http 协议访问网站时，都是明文的，包括密码，账号交易等机密信息，很容易会被泄露、窃取、篡改。安装 SSL 证书之后，使用 https 协议访问网站，可以激活用户浏览器到服务器的之间的 SSL 加密通道，实现高强度的双向加密传输，防止数据泄露、被篡改。



### https的ssl连接过程

- 客户端提交 http 请求
- 服务器相应 客户，并把证书发给客户端
- 客户端验证证书公钥的有效性
- 有效后，会生成一个会话密钥
- 用证书的公钥加密这个 会话密钥后，发送给服务器端
- 服务器收到后，用相对应的私钥解密，获得会话密钥
- 之后客户端与服务器端利用这个会话密钥加密要传输的数据进行通信







### 什么是阻塞和非阻塞以及同步和异步？

对于一次 I/O 来说，有数据就绪阶段以及数据读写两个阶段。

对于数据就绪阶段，根据系统 I/O 操作的就绪状态来区分阻塞和非阻塞。

- 阻塞 I/O是指，当用户线程发起 I/O 请求时，如果数据还未准备就绪，就会**阻塞**当前线程，让出 CPU
- 非阻塞 I/O 是指，当用户线程发起 I/O 请求时，如果数据还未准备就绪，也**不会阻塞**当前线程，可以继续执行后续的任务

对于数据读写阶段，根据系统 I/O 响应方式不同来区分同步和异步

- 同步 I/O 是指，当用户线程发起 I/O 请求时，数据已经准备好了，需要把内核空间的数据拷贝到用户空间，此时用户线程会**等待拷贝完成**
- 异步 I/O 是指，当用户线程发起 I/O 请求时，数据已经准备好了，需要把内核空间的数据拷贝到用户空间，此时用户线程**不会等待拷贝完成**

同步 I/O 就是注册可读事件，由线程调用函数读取。异步就是通过 aio_read 函数，告诉内核，缓冲区的地址，内核数据拷贝完成后通知线程



### Socket缓冲区

Socket 有一个缓冲区，send 的数据 buffer，它会先发到缓冲区里面，然后由操作系统去调度发送。所以，send 返回成功，仅仅只是说明，数据放到缓冲区成功了，不代表对端接收了，更不代表对端应用程序正确处理了。所以我们会看到缓冲区不满的时候，send 函数很快就返回了，而缓冲区满的时候，send 函数会阻塞直到超时返回错误。recv 函数同理，实际上是从 socket 缓冲区获取数据到用户空间的 buffer 里面。（TCP 发过来的网络数据，系统将会放到缓冲区里面，直到 recv 函数去获取数据，才取出来，并且释放出空间）

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230509000233.png)





### webserver两种高效的事件处理模式？

服务器通常需要处理三类事件：I/O 事件，信号以及定时事件，两种高效的事件处理模式分别是 Reactor 和 Proactor。

**Reactor模式**，要求主线程只负责监听文件描述符上是否有事件发生，如果有的话，就把该事件通知给工作线程，将 socket 可读可写事件放入到请求队列中，交给工作线程处理。除此之外，主线程不做其他实质性的工作。读写数据，接受新的连接，以及处理客户请求均在工作线程中完成。

使用同步 I/O 实现 Reactor 模式的工作流程为：

1. 主线程向 epoll_wait 内核事件表内注册 socket 上的读就绪事件
2. 然后调用 epoll_wait 等待 socket 上有数据可读
3. 当 socket 上有数据可读的时候， epoll_wait 通知主线程，主线程把 socket 可读事件放入到请求队列
4. 然后唤醒一个工作线程，从 socket 上读取数据，处理客户请求，再往 epoll 内核事件表中注册该 socket 上的写就绪事件
5. 主线程调用 epoll_wait 等待 socket 可写
6. 当 socket 可写的时候， epoll_wait 通知主线程，主线程把 socket 可写事件放入到请求队列
7. 唤醒请求队列上的工作线程，向 socket 上写入服务器处理客户请求的结果

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230218204203.png)



**Proactor 模式**，把所有的 I/O 操作都交给主线程和内核去处理（进行读写操作），工作线程仅仅负责业务逻辑。

使用异步 I/O 实现 Proactor 模式的工作流程：

1. 主线程调用 aio_read 函数向内核注册 socket 上的读完成时间，并告诉内核用户读缓冲区的位置，以及读操作完成时通知应用程序的方式
2. 主线程继续处理其他逻辑
3. 当 socket 上的数据被读到用户缓冲区后，内核向应用程序发送一个信号，通知应用程序数据已经可用
4. 应用程序预先定义的信号处理函数选择一个工作线程处理客户请求，工作线程完成后，调用 aio_write 函数向内核注册 socket 上的写完成事件，并告诉内核用户写缓冲区的位置，以及写操作完成时通知应用程序的方式
5. 主线程继续处理其他逻辑
6. 当用户缓冲区的数据被写入到 socket 后，内核向应用程序发送信号，通知应用程序数据已经发送完啦
7. 应用程序预先定义的信号处理函数选择一个工作线程进行善后处理，比如决定是否关闭 socket 

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230218205644.png)



**二者区别：**在于 Reactor 模式的工作线程不仅负责业务逻辑处理，还需要完成数据的读写操作。而 Proactor 模式的工作线程仅负责业务逻辑处理。

**模拟 Proactor 模式：**用主线程来完成数据的读写过程，这样对于工作线程来说，就直接获得了数据读写的结果，只需要进行逻辑处理就行

使用同步 I/O 模型模拟的 Proactor 模式的工作流程如下

1. 主线程向 epoll 内核事件表注册 socket 上的读事件
2. 主线程调用 epoll_wait 等待 socket 上有数据可读
3. 当 socket 上有数据可读时，epoll_wait 通知主线程，主线程读取数据，然后封装成一个请求对象，插入到请求队列中
4. 唤醒一个工作线程，获得请求对象处理客户请求，然后向 epoll 内核事件表中注册 socket 上的写就绪事件
5. 主线程调用 epoll_wait 等待 socket 可写
6. 当 socket 可写时，epoll_wait 通知主线程，主线程向 socket 上写入服务器处理客户请求的结果

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230218210647.png)





### 信号

三种常见的信号：SIGHUP，SIGPIPE，SIGURG

SIGHUP:

- SIGHUP 信号在**用户终端连接(正常或非正常)结束**时发出, 通常是在终端的控制进程结束时, 通知同一session内的各个作业, 这时它们与控制终端不再关联. 系统对SIGHUP信号的**默认处理是终止收到该信号的进程**。

SIGPIPE:

- 当往一个写端关闭的管道或socket连接中连续写入数据时会引发SIGPIPE信号,引发SIGPIPE信号的写操作将设置errno为EPIPE。在TCP通信中，当通信的双方中的一方close一个连接时，若另一方接着发数据，根据TCP协议的规定，会收到一个RST响应报文，若再往这个服务器发送数据时，系统会发出一个SIGPIPE信号给进程，告诉进程这个连接已经断开了，不能再写入数据。

SIGURG:

- 内核通知应用程序带外数据到达的方式有两种：一种就是利用ＩＯ复用技术的系统调用（如select）在接受到带外数据时将返回，并向应用程序报告socket上的异常事件。 
- 另一种方法就是使用SIGURG信号。



### 说一下 ET，LT，one_shot

首先，ET 和 LT 可以理解为是事件层面的，例如当有 socket 的数据到达的时候，会产生 EPOLLIN 事件

如果是 ET（边缘触发），那么该事件仅仅通知一次，不管到达的数据是否读完，下一次都不会再产生 EPOLLIN 事件，因此需要一次读完

如果是 LT（电平触发），那么该事件会通知多次，只要数据没有读完，那么就会一直产生 EPOLLIN 事件通知 socket 读取数据

而 one_shot，是线程层面的，当已经读取完某个 socket 的 EPOLLIN 事件的数据之后，会插入到请求队列中。这时候会从线程池中选择一个线程进行数据的解析处理（例如解析 HTTP 报文，生成 HTTP 响应报文等）。如果这个时候该 socket 上再次有 EPOLLIN 事件，主线程读取完数据之后插入到请求队列，这时会选择另外一个线程处理该请求，那么就会出现两个线程同时处理一个 socket 的请求这种情况。我们的设想肯定是一个 socket 的数据在某一时刻只由一个 工作线程处理，于是使用 one_shot。如果该 socket 注册 one_shot 事件，它规定操作系统最多触发其上注册的一个可读、可写或者异常事件，当触发了 EPOLLIN 事件之后，那么即使有后续的数据过来，也不会产生 EPOLLIN 事件，只有前面的线程处理完数据之后，才会重新注册 one_shot 事件。从而保证每个 socket 的数据不会**同时**被两个线程处理。

**一个socket在不用时期可以由不同工作线程处理，但同一时刻只有一个线程为之服务，保证了连接的完整性，避免了很多可能的竟态条件。**



### 说一下 select、poll、epoll 的区别是什么

I/O 多路复用的想法是让一个进程/线程可以处理多个 I/O 事件

首先，它们是 linux 下的三种不同的 I/O 复用的方式

- select 使用线性表描述文件描述符的集合，文件描述符有上限，poll 使用链表来描述，而 epoll 底层通过红黑树来描述，并且维护一个 ready list，把事件表中已经就绪的事件添加到这里，在使用 epoll_wait 调用时，观察这个 list 中有没有数据
- 对于 select 和 poll 来说，所有的文件描述符都是在用户态被加入其文件描述符集合，每次调用都需要把整个集合拷贝到内核态；而 epoll 是把整个文件描述符集合维护在内核态，每次添加文件描述符都需要执行系统调用
- select 和 poll 的最大开销来自内核判断是否有文件描述符就绪这个过程：每次执行 select 或 poll 调用，就会遍历整个文件描述符集合来判断是否有文件描述符就绪。而 epoll 不用，当有活动产生时，会自动触发 epoll 回调函数通知 epoll 文件描述符，然后内核把这些就绪的文件描述符放到 ready list 中等待 epoll_wait 调用
- select 和 poll 只能在 LT 模式下工作，而 epoll 同时支持 LT 和 ET 模式
- 当检测的文件描述符较少时，且每个文件描述符都比较活跃的情况下， select 和 poll 的效率较高。当监听的文件描述符较多且不太活跃的情况下，使用 epoll 较好



### 数据库登录说一下？

数据库登录分为

- 载入数据表，把数据库中的用户名和密码提取出来，用map容器存储
- 提取用户名和密码，通过解析请求报文的消息体，得到用户输入的用户名和密码
- 注册和登录校验，根据解析出来的用户名和密码，通过在 map 容器中查找，如果找得到说明是存在的，登录成功。注册的时候也会进行匹配，如果是一样的，说明存在相同的用户名，会注册失败
- 页面跳转，当登录成功时，会根据结果进行页面的跳转



### 你这个保存状态了吗？如果要保存，你会怎么做？（cookie和session）

Cookie 是一小段的文本信息。当客户端请求服务器的时候，如果服务器需要记录该用户的状态以及登录情况，就会在 response 的时候向客户端浏览器颁发一个 Cookie。客户端浏览器会把 Cookie 保存起来，当浏览器再次请求该服务器的时候，客户端会带上这一段 Cookie。然后服务器检查该 Cookie ，用来识别用户状态



Session是另外一种机制，不同的是 Cookie 保存在客户端浏览器上，而 Session 保存在服务器上，客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上，这就是 Session，客户端浏览器再次访问时只需要从该Session中查找该客户的状态就可以了。



### 登录中的用户名和密码你是load到本地，然后使用map匹配的，如果有10亿数据，即使l0ad到本地后hash，也是很耗时的，你要怎么优化？

- 数据结构的优化：为了保证数据库的一致性和完整性，在逻辑设计的时候会设计较多的表间关联，尽可能的降低数据的冗余
- 数据查询的优化：保证在实现功能的基础上，尽量减少对数据库的访问次数；通过搜索参数，尽量减少对表的访问行数，最小化结果集，从而减轻网络负担。
- 算法的优化：尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。.使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效
- 建立高效的索引：创建索引一般有以下两个目的：维护被索引列的唯一性和提供快速访问表中数据的策略。大型数据库有两种索引即簇索引和非簇索引，一个没有簇索引的表是按堆结构存储数据，所有的数据均添加在表的尾部，而建立了簇索引的表，其数据在物理上会按照簇索引键的顺序存储，一个表只允许有一个簇索引

对于大数据遍历的方法就是进行 hash，利用 hash 建立多级索引的方式加快用户验证

首先，把10亿用户信息，利用大致缩小 1000 倍的 hash 算法进行 hash，这时就获得了 100 万的 hash 数据，每一个 hash 数据代表着一个用户信息快（一级）

然后，再分别对这 100 万的 hash 数据再进行 hash，例如最后剩下 1000 个 hash 数据（二级）

在这种方式下，服务器只需要保存 1000 个二级 hash 数据，当用户请求登录的时候，先对用户信息进行一次 hash，找到对应信息块（二级？），再读取其对应的一级信息块，最终找到对应的用户数据



### 用的MySQL呀，redis了解吗？用过吗？

- 类型：MySQL是关系型数据库，主要用于存储持久化数据，把数据存储在硬盘中，读取速度慢。Redis 是 NOSQL，非关系型数据库，也就是缓存数据库，把数据存储到缓存中，读取速度快，但是保存的时间有限
- 运行机制：MySQL每次访问数据库的时候，都存在着 I/O 操作，如果反复频繁的访问数据库，会导致运行效率过慢，数据库的负载过高。Redis使用缓存，当浏览器执行请求时，首先会在缓存中进行查找，如果存在就获取，否则就访问数据库，读取速度快





### 为什么要用定时器？

处理定时任务，或者非活跃连接，节省系统资源



### 说一下定时器的工作原理

服务器的主循环为每个到来的连接创建一个定时器，并对每个连接进行定时，然后利用升序时间链表容器把所有的定时器串联起来。

然后利用 alarm 函数周期行地触发 SIGALRM 信号，信号处理函数就是利用管道，把该信号传递给主循环。主循环接收到信号事件，然后判断，如果是 SIGALRM 信号，就调用链表容器进行一次 tick()，该函数就是从头开始向后检查，如果有定时器的连接超时了，就会调用毁掉函数，释放连接资源。

当连接有数据处理的时候，会重置定时器的过期时间



### 双向链表啊，删除和添加的时间复杂度说一下？还可以优化吗？

刚好在头结点：添加是 O(1)，删除是 O(1)

刚好在尾节点：添加是 O(n)，删除是 O(1)

平均： 添加是 O(n)， 删除是 O(1)

因为从容器里面删除定时器的时候，是指定的 timer 



优化：

1. 在双向链表的基础上优化，添加在尾节点的事件复杂度可以优化，在添加新的定时器的时候，除了检测新定时器是否在小于头结点定时器的时间外，再先检测新定时器是否在大于尾节点定时器的事件，都不符合再使用常规插入？？？？？？？？？？？？？？？？？
2. 不使用双向链表，使用最小堆结构可以进行优化



### 最小堆优化？说一下时间复杂度和工作原理

时间复杂度：添加 O(lgn)，删除 O(1)

工作原理：

把所有定时器中超时事件最小的定时器的超时值作为 alarm 函数的定时值，这样，一旦定时任务处理函数 tick（） 被调用，超时时间最小的定时器必然到期，就可以在 tick函数中处理该定时器，然后，再次从剩余的定时器中找出超时事件最小的一个堆，并把这段最小时间设置为下一次 alarm 函数的定时值，这样就实现了较为精确的定时





### 说下你的日志系统的运行机制？

单例模式（局部静态变量懒汉模式）获取实例

首先主线程一开始对日志类进行初始化，Log::get_instance() -> init() ，初始化实例。初始化之后，服务器按照当前启动的时间创建日志文件（前缀为时间，后缀是自定义的 log 文件名，并记录创建日志的时间 day 和行数 count ）。如果是异步（通过是否设置队列大小判断是否异步，0为同步），工作线程将要写的内容放进阻塞队列，还创建了写线程用于在阻塞队列里取出一个内容（指针），写入日志

其他功能模块调用 write_log() 函数写日志，实现了日志的分级，份文件，按天按行分类的格式化输出内容



### 为什么要异步？和同步的区别是什么？

因为同步日志，写入函数与工作线程串行执行，由于涉及到 I/O 操作，在单条日志比较大的时候，同步模式会组设整个处理流程，服务器所能处理的并发能力将会下降，尤其是在峰值的时候，写日志可能会成为系统的瓶颈

而异步日志采用了 生产者-消费者 模型，工作线程把所写的日志内容先存入缓冲区，写线程从缓冲区中取出内容，写入日志，并烦恼歌力较高



### 什么是生产者消费者模式？

某个模块负责产生数据，这些数据由另外一个模块来负责处理（此处的模块是广义的，可以是进程，线程，类，函数等）。

产生数据的模块，就形象的称为 生产者，处理数据的模块，称为消费者

另外还需要一个缓冲区处于生产者和消费者之间，作为一个中介。生产者把数据放入缓冲区，而消费者从缓冲区取出数据。

![](https://cdn.jsdelivr.net/gh/vaesong/Images//20230318153820.png)



### 缓冲区用什么实现？

缓冲区使用循环数组实现队列，作为二者共享的缓冲区



### 现在你要监控一台服务器的状态，输出监控日志，请问如何将该日志分发到不同的机器上

同一个机器：使用观察者模式（有的叫发布订阅模式）

多个机器：借助 redis 数据库的消息队列的发布订阅模式，实现分布式日志系统

为了便于故障排查，或服务器状态分析，看是否需要维护；可以使用消息队列进行消息的分发，例如mqtt、rabitmq等等



### **Webbench是什么，介绍一下原理**？

Webbench是一款轻量级的网址压力测试工具，可以实现高达3万的并发测试

原理：父进程 fork 若干个子进程，每个子进程在用户要求的时间或者默认的时间内对目标 web 循环发出实际访问请求，父子进程通过管道进行通信，子进程通过管道写端向父进程传递在若干次请求访问完毕后记录到的总信息。父进程通过管道读取子进程附送的相关信息，父进程在时间到后结束，父进程在所有子进程退出后同济并给用户显示最后的测试结果，然后退出



### RAII 是什么？

当我们在获取资源的时候，经常在使用之后会忘记销毁申请的资源，于是引入了 RAII 机制

该方法就是设计一个封装资源的类，在类的构造函数里面，进行初始化，获取资源。在类的析构函数里进行资源的释放

这样操作之后，在局部作用域对类进行实例化，这样就会自动获得资源，当离开作用域之后，该实例被自动销毁，调用析构函数，从而自动释放资源









# 设计模式







# MPRPC

RPC 是远程过程调用（Remote Procedure Call）

### 为什么要做这个项目？

集群：每一台服务器独立的运行一个工程的所有模块

优点：

- 多个服务器，可以同时承受的并发量大大增加

缺点：

- 当某个模块出现问题时，项目代码需要整体重新编译，而且需要多次部署
- 仍然不能解决 不同模块需要不同的硬件资源



分布式：一个工程拆分成多个模块，每一个或多个模块独立部署在一个服务器主机上，所有服务器协同工作共同提供服务，每一台服务器称作分布式的一个节点，根据节点的并发要求，对一个节点可以再做节点模块集群部署

优点：

- 一个服务器节点集群部署，可以提高并发量
- 每个服务器节点出现问题，只需要在该节点上重新编译和部署
- 可以解决不同模块对于不同硬件资源的需求



### 简单描述项目、实现了怎样的功能？采用了哪些技术栈

本项目是使用 C++ 语言开发的一种 RPC 分布式服务框架， 使用 CMake 在 Linux 环境下构建编译环境。它可以把系统的本地方法调用重构为 基于TCP网络通信的RPC远程方法调用，该框架适用于将单体架构系统拆分为基于分布式微服务调用的部署，通过部署多份来提升系统整体的并发性能，具有模块服务独立升级和服务间解耦的优势

该项目的网络层基于高并发的 Reactor 网络模型 muduo 开源网络库实现，使得对于网络 I/O 层和RPC方法调用处理层进行代码解耦变得更加容易，并且具有较好的并发性

RPC 方法调用使用 protobuf 进行相关数据的序列化和反序列化，可以直接在同构和异构系统中进行调用（一端是C++写的，另外一端是Java、Go等，但都是基于 protobuf 协议进行通信）。

微服务的服务注册、服务发现等功能是基于 Zookeeper 实现的，Zookeeper 本身提供了C 的API，可以通过 API 与Zookeeper 服务器进行通信



### 有哪些常见的 RPC 框架？

**Dubbo：**Apache Dubbo 是一款微服务框架，为大规模微服务实践提供高性能 RPC 通信、流量治理、可观测性等解决方案， 涵盖 Java、Golang 等多种语言 SDK 实现

Dubbo 提供了从服务定义、服务发现、服务通信到流量管控等几乎所有的服务治理能力，支持 Triple 协议（基于 HTTP/2  之上定义的下一代 RPC 通信协议）、应用级服务发现、Dubbo Mesh （Dubbo3 赋予了很多云原生友好的新特性）等特性

**Motan：** Motan 是新浪微博开源的一款 RPC 框架

**gRPC：** Google 开源的一个高性能、通用的开源 RPC 框架。其由主要面向移动应用开发并基于 HTTP/2 协议标准而设计（支持双向流、消息头压缩等功能，更加节省带宽），基于 ProtoBuf 序列化协议开发，并且支持众多开发语言

**Thrift：** Facebook 开源的跨语言的 RPC 通信框架





### **为什么要进行序列化和反序列化？**

将结构体转为二进制数组的过程就叫 **序列化** ，反过来将二进制数组复原成结构体的过程叫 **反序列化**

- 压缩数据，加快网络传输
- 解决异构系统的数据传输，比如大小端、远端的持久存储
- 解决内存中数据结构到字节序列的映射过程中，如何保留各个结构和字段间的关系



### 消息传输为什么用 protobuf ，而不用 json？

- 效率更高，protobuf 是基于二进制序列化数据，它的编码解码效率更高，而 json 是纯文本的
- 传输的数据量更少，
- 语言支持和工具生态好，protobuf 支持多种语言，C++，Java，Python，Go 等，并且提供了很多封装的接口，只需要关注服务管理和 rpc 通信流程的开发





### 项目中采用线程同步解决了哪些问题？

微服务进程启动后，在代码上需要调用 zoo_create 方法连接 zookee server，但是全局的 watcher 是在另外一个线程中工作的，Zookeeper server 连接成功是通过 watcher 回调来通知应用程序的，所有这里使用了线程间的 sem 信号量同步等待 watcher 中相应 zk 连接成功后，程序再继续执行下面的操作



### 对这些服务器中间件有更深层的了解吗，还了解哪些功能？

服务器中间件了解过



### zookeeper 在你的项目中起到什么作用？

每个 server 进程启动后，都需要连接Zookeeper，在上面注册自己对外提供的 RPC 服务，这样的话，当 RPC 方法调用的时候，会去 Zookeeper 上查询一下该 RPC方法所在的 server 节点，拉取服务所在节点的 ip 地址和 port 信息，然后进行远程服务调用，所以 Zookeeper 在项目里主要做一些服务注册和服务发现

服务治理的内容除了服务注册、服务发现，常见的还有服务熔断，服务降级等等，一般都会实现一个统一的微服务网关做这些处理，但是该项目还没有涉及到这么复杂的需求，所以后续可以再研究一下大型的开源代码



### 项目有什么需要改进的地方？

目前主要是做 RPC 框架设计和服务调用的实现细节上面，暂时还没有做压力测试，后续可以使用专业的 Jmeter 或者 LoadRunner 工具进行压力测试，看能否找到一些瓶颈以及代码可以优化的地方

可以在分布式框架上集成更多的功能，比如通过一个分布式服务治理网关，实现流量监控、调用监控、日志等功能



### 项目优势在哪里？

后台服务设计部署主要就三种类型：单体、集群、分布式微服务

对于 protobuf ，知道了其应用场景和优势，提供了基于 rpc service 方法调用的



### 项目中遇到的问题？

首先是关于 Zookeeper 和 protobuf 的使用，尤其是 Zookeeper 的全局 watcher 这一块，一开始也是没有意识到需要同步的操作，后来查阅资料解决了该问题

还有对于 bind 绑定器的绑定一个函数对象的时候，用 const 和不用 const 修饰的函数是构成重载的

实现项目的过程中，



### 假如现在需要用 json 作为数据传输序列，项目哪里需要改动，怎么改动？

在数据序列化和反序列化方面直接修改成 json 处理就行

但是 json 没有办法实现 protobuf 的 service rpc 方法的定义，无法生成特有的封装好的 rpc 方法调用的框架， json 没有这种机制，他只是简单的序列化和反序列化协议， 它不能像 protobuf 那样生成一套封装好的 rpc 代码调用框架

所以要换成 json 的话，需要自己去进行实现

另外 json 发送的是文本数据，而 protobuf 传输的是二进制数据，在解决 tcp 粘包问题的代码上，也需要进行相应的修改



